{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  \n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, EasyEnsembleClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler # to check again how to use this in a pipeline \n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOCCS.ID</th>\n",
       "      <th>GP1</th>\n",
       "      <th>GP2</th>\n",
       "      <th>GP3</th>\n",
       "      <th>GP4</th>\n",
       "      <th>GP5</th>\n",
       "      <th>GP6</th>\n",
       "      <th>GP7</th>\n",
       "      <th>GP8</th>\n",
       "      <th>GP9</th>\n",
       "      <th>...</th>\n",
       "      <th>GP18</th>\n",
       "      <th>GP19</th>\n",
       "      <th>GP20</th>\n",
       "      <th>GP21</th>\n",
       "      <th>GP22</th>\n",
       "      <th>GP23</th>\n",
       "      <th>GP24</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age at sample</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRC_4468</th>\n",
       "      <td>324640002</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>15.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>22.06</td>\n",
       "      <td>9.67</td>\n",
       "      <td>...</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>F</td>\n",
       "      <td>20.747945</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_8680</th>\n",
       "      <td>236220199</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.81</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>18.93</td>\n",
       "      <td>7.31</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.86</td>\n",
       "      <td>F</td>\n",
       "      <td>22.413699</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_8879</th>\n",
       "      <td>381640099</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20.42</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.45</td>\n",
       "      <td>17.99</td>\n",
       "      <td>8.82</td>\n",
       "      <td>...</td>\n",
       "      <td>12.89</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.01</td>\n",
       "      <td>M</td>\n",
       "      <td>27.789041</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_8260</th>\n",
       "      <td>406120111</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>22.48</td>\n",
       "      <td>10.54</td>\n",
       "      <td>...</td>\n",
       "      <td>12.34</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.71</td>\n",
       "      <td>F</td>\n",
       "      <td>31.410959</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_8292</th>\n",
       "      <td>382140007</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>15.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.36</td>\n",
       "      <td>14.80</td>\n",
       "      <td>9.40</td>\n",
       "      <td>...</td>\n",
       "      <td>12.45</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.17</td>\n",
       "      <td>M</td>\n",
       "      <td>66.624658</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7434</th>\n",
       "      <td>237000023</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.42</td>\n",
       "      <td>22.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>6.03</td>\n",
       "      <td>1.36</td>\n",
       "      <td>17.55</td>\n",
       "      <td>10.24</td>\n",
       "      <td>...</td>\n",
       "      <td>6.89</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.39</td>\n",
       "      <td>F</td>\n",
       "      <td>61.016438</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7051</th>\n",
       "      <td>238500001</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.71</td>\n",
       "      <td>23.56</td>\n",
       "      <td>0.39</td>\n",
       "      <td>8.11</td>\n",
       "      <td>0.97</td>\n",
       "      <td>17.64</td>\n",
       "      <td>8.48</td>\n",
       "      <td>...</td>\n",
       "      <td>7.16</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.77</td>\n",
       "      <td>F</td>\n",
       "      <td>60.819178</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7397</th>\n",
       "      <td>252000007</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.67</td>\n",
       "      <td>42.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>13.80</td>\n",
       "      <td>8.33</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.35</td>\n",
       "      <td>M</td>\n",
       "      <td>61.221918</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7981</th>\n",
       "      <td>257000022</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>22.65</td>\n",
       "      <td>0.29</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>18.47</td>\n",
       "      <td>9.29</td>\n",
       "      <td>...</td>\n",
       "      <td>9.13</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.83</td>\n",
       "      <td>F</td>\n",
       "      <td>61.142466</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7767</th>\n",
       "      <td>263500021</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>28.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.34</td>\n",
       "      <td>18.85</td>\n",
       "      <td>10.46</td>\n",
       "      <td>...</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.89</td>\n",
       "      <td>M</td>\n",
       "      <td>60.986301</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1298 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SOCCS.ID   GP1   GP2   GP3    GP4   GP5   GP6   GP7    GP8    GP9  \\\n",
       "Sample                                                                         \n",
       "CRC_4468  324640002  0.17  0.37  0.52  15.35  0.27  3.74  0.45  22.06   9.67   \n",
       "CRC_8680  236220199  0.17  0.26  0.26   8.81  0.18  3.20  0.47  18.93   7.31   \n",
       "CRC_8879  381640099  0.13  0.48  0.30  20.42  0.25  4.16  0.45  17.99   8.82   \n",
       "CRC_8260  406120111  0.19  0.18  0.31  12.42  0.35  2.61  0.62  22.48  10.54   \n",
       "CRC_8292  382140007  0.18  0.39  0.66  15.38  0.46  4.80  0.36  14.80   9.40   \n",
       "...             ...   ...   ...   ...    ...   ...   ...   ...    ...    ...   \n",
       "CRC_7434  237000023  0.16  1.33  0.42  22.45  0.51  6.03  1.36  17.55  10.24   \n",
       "CRC_7051  238500001  0.26  1.64  0.71  23.56  0.39  8.11  0.97  17.64   8.48   \n",
       "CRC_7397  252000007  0.40  0.57  0.67  42.35  0.36  6.18  0.50  13.80   8.33   \n",
       "CRC_7981  257000022  0.09  0.38  0.37  22.65  0.29  6.48  0.43  18.47   9.29   \n",
       "CRC_7767  263500021  0.12  0.39  0.39  28.34  0.29  6.47  0.34  18.85  10.46   \n",
       "\n",
       "          ...   GP18  GP19  GP20  GP21  GP22  GP23  GP24  Gender  \\\n",
       "Sample    ...                                                      \n",
       "CRC_4468  ...  11.50  1.54  0.48  0.50  0.07  0.95  0.96       F   \n",
       "CRC_8680  ...  13.86  2.57  0.70  1.28  0.28  1.62  1.86       F   \n",
       "CRC_8879  ...  12.89  1.79  0.34  0.86  0.11  2.36  2.01       M   \n",
       "CRC_8260  ...  12.34  2.01  0.52  0.65  0.09  1.83  1.71       F   \n",
       "CRC_8292  ...  12.45  2.15  1.13  1.46  0.37  2.26  2.17       M   \n",
       "...       ...    ...   ...   ...   ...   ...   ...   ...     ...   \n",
       "CRC_7434  ...   6.89  2.40  0.80  1.75  0.22  1.98  2.39       F   \n",
       "CRC_7051  ...   7.16  2.44  0.33  0.93  0.28  1.30  2.77       F   \n",
       "CRC_7397  ...   5.71  1.17  0.41  0.90  0.11  1.29  1.35       M   \n",
       "CRC_7981  ...   9.13  2.45  0.30  0.75  0.10  1.71  2.83       F   \n",
       "CRC_7767  ...   6.55  1.49  0.34  0.91  0.10  1.31  1.89       M   \n",
       "\n",
       "          Age at sample   Status  \n",
       "Sample                            \n",
       "CRC_4468      20.747945  Control  \n",
       "CRC_8680      22.413699  Control  \n",
       "CRC_8879      27.789041  Control  \n",
       "CRC_8260      31.410959  Control  \n",
       "CRC_8292      66.624658  Control  \n",
       "...                 ...      ...  \n",
       "CRC_7434      61.016438   Cancer  \n",
       "CRC_7051      60.819178   Cancer  \n",
       "CRC_7397      61.221918   Cancer  \n",
       "CRC_7981      61.142466   Cancer  \n",
       "CRC_7767      60.986301   Cancer  \n",
       "\n",
       "[1298 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('Cleaned_Dataframe_1298_datapoints.xlsx')\n",
    "df1.set_index('Sample',inplace=True)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chnging type of data to 'category' from 'object'\n",
    "df1.Gender = df1.Gender.astype('category')\n",
    "df1.Status = df1.Status.astype('category')\n",
    "\n",
    "df_cancer = df1.loc[df1['Status'] == 'Cancer']\n",
    "df_control = df1.loc[df1['Status'] == 'Control']\n",
    "df_cancer_small = df_cancer.sample(n=538, random_state = 100)\n",
    "\n",
    "df1_balanced = pd.concat([df_cancer_small, df_control])\n",
    "#separate cancer markers and input data\n",
    "df1_outputs= df1_balanced['Status']\n",
    "df1_inputs = df1_balanced.drop(['SOCCS.ID','Status'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1_inputs, df1_outputs, random_state=100, stratify=df1_outputs, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_function(model, parameters, X_train, y_train):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(steps=[('preprosessor', preprocessor), ('algorithm', model)])\n",
    "                        #RandomUnderSampler(random_state = 42))\n",
    "    \n",
    "    search = GridSearchCV(pipeline, parameters, cv=StratifiedKFold(5), n_jobs=-1)\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    return(best_model, search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_function(model, tune_parameters, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "\n",
    "    X_train_sc = preprocessor.fit_transform(X_train)\n",
    "    X_test_sc = preprocessor.transform(X_test)\n",
    "    \n",
    "    #Finding the best parameters \n",
    "    best_model, search = grid_function(model, tune_parameters, X_train, y_train)\n",
    "    print (best_model._final_estimator)\n",
    "    \n",
    "    #Make prediction using the best model\n",
    "    best_model._final_estimator.fit(X_train_sc, y_train)\n",
    "    y_pred = best_model._final_estimator.predict(X_test_sc)\n",
    "\n",
    "    #Print test performance of the model\n",
    "    print()\n",
    "    print('Model Performance')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "rf_tune = { \n",
    "    'algorithm__n_estimators': [100,200, 300, 400, 500, 1000],\n",
    "    'algorithm__max_depth' : [4,5,6,7,8,9,10],\n",
    "    'algorithm__bootstrap': [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.033877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>0.027597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.036744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>0.066861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>0.034433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.032346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>0.025464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.033640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.037295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>0.027915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.033625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.039757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.031484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.103312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.067555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>0.047268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.029147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.045166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>0.029913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>0.031353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.034286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.032958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.032955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.024434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.056999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at sample</th>\n",
       "      <td>0.003617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Importance\n",
       "GP1              0.033877\n",
       "GP2              0.027597\n",
       "GP3              0.036744\n",
       "GP4              0.066861\n",
       "GP5              0.034433\n",
       "GP6              0.032346\n",
       "GP7              0.025464\n",
       "GP8              0.033640\n",
       "GP9              0.037295\n",
       "GP10             0.027915\n",
       "GP11             0.033625\n",
       "GP12             0.039757\n",
       "GP13             0.031484\n",
       "GP14             0.103312\n",
       "GP15             0.067555\n",
       "GP16             0.047268\n",
       "GP17             0.029147\n",
       "GP18             0.045166\n",
       "GP19             0.029913\n",
       "GP20             0.031353\n",
       "GP21             0.034286\n",
       "GP22             0.032958\n",
       "GP23             0.032955\n",
       "GP24             0.024434\n",
       "Gender           0.056999\n",
       "Age at sample    0.003617"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_rf, search_rf = grid_function(rf, rf_tune, X_train, y_train)\n",
    "rf_ranking = pd.DataFrame(best_model_rf._final_estimator.feature_importances_, index=X_train.columns)\n",
    "rf_ranking.columns = ['Importance']\n",
    "rf_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=7, n_estimators=300, random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.66      0.67      0.67       162\n",
      "     Control       0.67      0.66      0.66       161\n",
      "\n",
      "    accuracy                           0.67       323\n",
      "   macro avg       0.67      0.67      0.67       323\n",
      "weighted avg       0.67      0.67      0.67       323\n",
      "\n",
      "[[109  53]\n",
      " [ 55 106]]\n"
     ]
    }
   ],
   "source": [
    "pred_function(rf, rf_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paramters\n",
    "svm_tune = { \n",
    "    'algorithm__kernel': ['linear'], \n",
    "    'algorithm__degree' : [2,3,4],\n",
    "    'algorithm__C':[0, 1.0],\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.68521854 0.68521854 0.68521854]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(degree=2, kernel='linear', random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.67      0.63      0.65       162\n",
      "     Control       0.65      0.68      0.66       161\n",
      "\n",
      "    accuracy                           0.66       323\n",
      "   macro avg       0.66      0.66      0.66       323\n",
      "weighted avg       0.66      0.66      0.66       323\n",
      "\n",
      "[[102  60]\n",
      " [ 51 110]]\n"
     ]
    }
   ],
   "source": [
    "pred_function(svm, svm_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.68521854 0.68521854 0.68521854]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.230414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>-0.275549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.034641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>-0.293048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>-0.199033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.661814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>-0.292923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.421532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.592295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>-0.739226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.383759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.588024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.093458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>-0.495661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>1.145960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>-0.895713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>-0.311560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.591921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>-0.418881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>-0.213159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>-0.159505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.428195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.503808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.306145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.230773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at sample</th>\n",
       "      <td>0.016613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Importance\n",
       "GP1              0.230414\n",
       "GP2             -0.275549\n",
       "GP3              0.034641\n",
       "GP4             -0.293048\n",
       "GP5             -0.199033\n",
       "GP6              0.661814\n",
       "GP7             -0.292923\n",
       "GP8              0.421532\n",
       "GP9              0.592295\n",
       "GP10            -0.739226\n",
       "GP11             0.383759\n",
       "GP12             0.588024\n",
       "GP13             0.093458\n",
       "GP14            -0.495661\n",
       "GP15             1.145960\n",
       "GP16            -0.895713\n",
       "GP17            -0.311560\n",
       "GP18             0.591921\n",
       "GP19            -0.418881\n",
       "GP20            -0.213159\n",
       "GP21            -0.159505\n",
       "GP22             0.428195\n",
       "GP23             0.503808\n",
       "GP24             0.306145\n",
       "Gender           0.230773\n",
       "Age at sample    0.016613"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_svm, search_svm = grid_function(svm, svm_tune, X_train, y_train)\n",
    "\n",
    "svm_ranking_table = pd.DataFrame(best_model_svm._final_estimator.coef_[0], index=X_train.columns)\n",
    "svm_ranking_table.columns = ['Importance']\n",
    "svm_ranking_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "xgb_tune = { \n",
    "    'algorithm__eta': [0.01, 0.05, 0.1, 0.3, 0.5, 1], #Step size shrinkage used in update to prevents overfitting\n",
    "    'algorithm__max_depth' : [4,5,6,7,8,9,10],\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:18:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.036285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>0.029896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.042393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>0.053603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>0.034583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.027039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>0.021109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.031484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.030842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>0.029955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.036823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.030735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.033551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.096878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.064561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>0.043090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.032999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.025488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>0.030557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>0.030810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.040709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.039722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.037328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.030339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.045914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at sample</th>\n",
       "      <td>0.043307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Importance\n",
       "GP1              0.036285\n",
       "GP2              0.029896\n",
       "GP3              0.042393\n",
       "GP4              0.053603\n",
       "GP5              0.034583\n",
       "GP6              0.027039\n",
       "GP7              0.021109\n",
       "GP8              0.031484\n",
       "GP9              0.030842\n",
       "GP10             0.029955\n",
       "GP11             0.036823\n",
       "GP12             0.030735\n",
       "GP13             0.033551\n",
       "GP14             0.096878\n",
       "GP15             0.064561\n",
       "GP16             0.043090\n",
       "GP17             0.032999\n",
       "GP18             0.025488\n",
       "GP19             0.030557\n",
       "GP20             0.030810\n",
       "GP21             0.040709\n",
       "GP22             0.039722\n",
       "GP23             0.037328\n",
       "GP24             0.030339\n",
       "Gender           0.045914\n",
       "Age at sample    0.043307"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_xgb, search_xgb = grid_function(xgb, xgb_tune, X_train, y_train)\n",
    "xgb_ranking = pd.DataFrame(best_model_xgb._final_estimator.feature_importances_, index=X_train.columns)\n",
    "xgb_ranking.columns = ['Importance']\n",
    "xgb_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eta=0.05, gamma=0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.0500000007, max_delta_step=0, max_depth=4,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "[23:19:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.66      0.65      0.65       162\n",
      "     Control       0.65      0.66      0.65       161\n",
      "\n",
      "    accuracy                           0.65       323\n",
      "   macro avg       0.65      0.65      0.65       323\n",
      "weighted avg       0.65      0.65      0.65       323\n",
      "\n",
      "[[105  57]\n",
      " [ 55 106]]\n"
     ]
    }
   ],
   "source": [
    "pred_function(xgb, xgb_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=2, kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_svm._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, n_estimators=300, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_rf._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_evaluate(df, best_model_rf, best_model_svm, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "\n",
    "    X_train_sc = preprocessor.fit_transform(X_train)\n",
    "    X_test_sc = preprocessor.transform(X_test)\n",
    "    \n",
    "    estimators = [('rf', best_model_rf._final_estimator),\n",
    "                 ('svm', best_model_svm._final_estimator),\n",
    "                 ('xgb', best_model_xgb._final_estimator)]\n",
    "    \n",
    "    sc = StackingClassifier(estimators = estimators, \n",
    "                           final_estimator = LogisticRegression())\n",
    "    \n",
    "    sc.fit(X_train_sc, y_train)\n",
    "    \n",
    "    y_pred = sc.predict(X_test_sc)\n",
    "    \n",
    "    #Trying to figure out extract the prediction into a table\n",
    "    y_pred_df = pd.DataFrame(data = y_pred, columns = ['Prediction']\n",
    "                             , index = X_test.index.copy())\n",
    "    \n",
    "    df_out = pd.merge(df1, y_pred_df, how = 'left', \n",
    "                      left_index = True, right_index = True)\n",
    "    \n",
    "    #Print test performance of the model\n",
    "    print()\n",
    "    print('Model Performance')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.67      0.65      0.66       162\n",
      "     Control       0.66      0.68      0.67       161\n",
      "\n",
      "    accuracy                           0.67       323\n",
      "   macro avg       0.67      0.67      0.67       323\n",
      "weighted avg       0.67      0.67      0.67       323\n",
      "\n",
      "[[106  56]\n",
      " [ 52 109]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOCCS.ID</th>\n",
       "      <th>GP1</th>\n",
       "      <th>GP2</th>\n",
       "      <th>GP3</th>\n",
       "      <th>GP4</th>\n",
       "      <th>GP5</th>\n",
       "      <th>GP6</th>\n",
       "      <th>GP7</th>\n",
       "      <th>GP8</th>\n",
       "      <th>GP9</th>\n",
       "      <th>...</th>\n",
       "      <th>GP19</th>\n",
       "      <th>GP20</th>\n",
       "      <th>GP21</th>\n",
       "      <th>GP22</th>\n",
       "      <th>GP23</th>\n",
       "      <th>GP24</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age at sample</th>\n",
       "      <th>Status</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRC_4468</th>\n",
       "      <td>324640002</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>15.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>22.06</td>\n",
       "      <td>9.67</td>\n",
       "      <td>...</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>F</td>\n",
       "      <td>20.747945</td>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_8680</th>\n",
       "      <td>236220199</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.81</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>18.93</td>\n",
       "      <td>7.31</td>\n",
       "      <td>...</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.86</td>\n",
       "      <td>F</td>\n",
       "      <td>22.413699</td>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_8879</th>\n",
       "      <td>381640099</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20.42</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.45</td>\n",
       "      <td>17.99</td>\n",
       "      <td>8.82</td>\n",
       "      <td>...</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.01</td>\n",
       "      <td>M</td>\n",
       "      <td>27.789041</td>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_8260</th>\n",
       "      <td>406120111</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>22.48</td>\n",
       "      <td>10.54</td>\n",
       "      <td>...</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.71</td>\n",
       "      <td>F</td>\n",
       "      <td>31.410959</td>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_8292</th>\n",
       "      <td>382140007</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>15.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.36</td>\n",
       "      <td>14.80</td>\n",
       "      <td>9.40</td>\n",
       "      <td>...</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.17</td>\n",
       "      <td>M</td>\n",
       "      <td>66.624658</td>\n",
       "      <td>Control</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7434</th>\n",
       "      <td>237000023</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.42</td>\n",
       "      <td>22.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>6.03</td>\n",
       "      <td>1.36</td>\n",
       "      <td>17.55</td>\n",
       "      <td>10.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.39</td>\n",
       "      <td>F</td>\n",
       "      <td>61.016438</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7051</th>\n",
       "      <td>238500001</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.71</td>\n",
       "      <td>23.56</td>\n",
       "      <td>0.39</td>\n",
       "      <td>8.11</td>\n",
       "      <td>0.97</td>\n",
       "      <td>17.64</td>\n",
       "      <td>8.48</td>\n",
       "      <td>...</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.77</td>\n",
       "      <td>F</td>\n",
       "      <td>60.819178</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7397</th>\n",
       "      <td>252000007</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.67</td>\n",
       "      <td>42.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>13.80</td>\n",
       "      <td>8.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.35</td>\n",
       "      <td>M</td>\n",
       "      <td>61.221918</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7981</th>\n",
       "      <td>257000022</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>22.65</td>\n",
       "      <td>0.29</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>18.47</td>\n",
       "      <td>9.29</td>\n",
       "      <td>...</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.83</td>\n",
       "      <td>F</td>\n",
       "      <td>61.142466</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7767</th>\n",
       "      <td>263500021</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>28.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.34</td>\n",
       "      <td>18.85</td>\n",
       "      <td>10.46</td>\n",
       "      <td>...</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.89</td>\n",
       "      <td>M</td>\n",
       "      <td>60.986301</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1298 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SOCCS.ID   GP1   GP2   GP3    GP4   GP5   GP6   GP7    GP8    GP9  \\\n",
       "Sample                                                                         \n",
       "CRC_4468  324640002  0.17  0.37  0.52  15.35  0.27  3.74  0.45  22.06   9.67   \n",
       "CRC_8680  236220199  0.17  0.26  0.26   8.81  0.18  3.20  0.47  18.93   7.31   \n",
       "CRC_8879  381640099  0.13  0.48  0.30  20.42  0.25  4.16  0.45  17.99   8.82   \n",
       "CRC_8260  406120111  0.19  0.18  0.31  12.42  0.35  2.61  0.62  22.48  10.54   \n",
       "CRC_8292  382140007  0.18  0.39  0.66  15.38  0.46  4.80  0.36  14.80   9.40   \n",
       "...             ...   ...   ...   ...    ...   ...   ...   ...    ...    ...   \n",
       "CRC_7434  237000023  0.16  1.33  0.42  22.45  0.51  6.03  1.36  17.55  10.24   \n",
       "CRC_7051  238500001  0.26  1.64  0.71  23.56  0.39  8.11  0.97  17.64   8.48   \n",
       "CRC_7397  252000007  0.40  0.57  0.67  42.35  0.36  6.18  0.50  13.80   8.33   \n",
       "CRC_7981  257000022  0.09  0.38  0.37  22.65  0.29  6.48  0.43  18.47   9.29   \n",
       "CRC_7767  263500021  0.12  0.39  0.39  28.34  0.29  6.47  0.34  18.85  10.46   \n",
       "\n",
       "          ...  GP19  GP20  GP21  GP22  GP23  GP24  Gender  Age at sample  \\\n",
       "Sample    ...                                                              \n",
       "CRC_4468  ...  1.54  0.48  0.50  0.07  0.95  0.96       F      20.747945   \n",
       "CRC_8680  ...  2.57  0.70  1.28  0.28  1.62  1.86       F      22.413699   \n",
       "CRC_8879  ...  1.79  0.34  0.86  0.11  2.36  2.01       M      27.789041   \n",
       "CRC_8260  ...  2.01  0.52  0.65  0.09  1.83  1.71       F      31.410959   \n",
       "CRC_8292  ...  2.15  1.13  1.46  0.37  2.26  2.17       M      66.624658   \n",
       "...       ...   ...   ...   ...   ...   ...   ...     ...            ...   \n",
       "CRC_7434  ...  2.40  0.80  1.75  0.22  1.98  2.39       F      61.016438   \n",
       "CRC_7051  ...  2.44  0.33  0.93  0.28  1.30  2.77       F      60.819178   \n",
       "CRC_7397  ...  1.17  0.41  0.90  0.11  1.29  1.35       M      61.221918   \n",
       "CRC_7981  ...  2.45  0.30  0.75  0.10  1.71  2.83       F      61.142466   \n",
       "CRC_7767  ...  1.49  0.34  0.91  0.10  1.31  1.89       M      60.986301   \n",
       "\n",
       "           Status  Prediction  \n",
       "Sample                         \n",
       "CRC_4468  Control         NaN  \n",
       "CRC_8680  Control     Control  \n",
       "CRC_8879  Control         NaN  \n",
       "CRC_8260  Control     Control  \n",
       "CRC_8292  Control         NaN  \n",
       "...           ...         ...  \n",
       "CRC_7434   Cancer         NaN  \n",
       "CRC_7051   Cancer         NaN  \n",
       "CRC_7397   Cancer         NaN  \n",
       "CRC_7981   Cancer         NaN  \n",
       "CRC_7767   Cancer      Cancer  \n",
       "\n",
       "[1298 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_evaluate(df1, best_model_rf, best_model_svm, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
