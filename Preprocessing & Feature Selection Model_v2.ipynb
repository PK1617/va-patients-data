{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  \n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, EasyEnsembleClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler # to check again how to use this in a pipeline \n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Cleaned_Dataframe.xlsx')\n",
    "df.set_index('Sample',inplace=True)\n",
    "\n",
    "#chnging type of data to 'category' from 'object'\n",
    "df.Gender = df.Gender.astype('category')\n",
    "df.Status = df.Status.astype('category')\n",
    "\n",
    "#separate cancer markers and input data\n",
    "df_outputs= df['Status']\n",
    "df_inputs = df.drop('Status',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_inputs, df_outputs, random_state=100, stratify=df_outputs, test_size=0.3)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_function(model, parameters, X_train, y_train):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(steps=[('preprosessor', preprocessor), ('algorithm', model)])\n",
    "                        #RandomUnderSampler(random_state = 42))\n",
    "    \n",
    "    search = GridSearchCV(pipeline, parameters, cv=StratifiedKFold(5), n_jobs=-1)\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    return(best_model, search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_function(best_model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "\n",
    "    X_train_sc = preprocessor.fit_transform(X_train)\n",
    "    X_test_sc = preprocessor.transform(X_test)\n",
    "    \n",
    "    best_model._final_estimator.fit(X_train_sc, y_train)\n",
    "    \n",
    "    y_pred = best_model._final_estimator.predict(X_test_sc)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    #incorporate confusion matrix\n",
    "    \n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, tune_parameters, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    #Finding the best parameters \n",
    "    best_model, search = grid_function(model, tune_parameters, X_train, y_train)\n",
    "    print (best_model._final_estimator)\n",
    "   \n",
    "    #Calculate the labels for the test set\n",
    "    best_model_predictions = best_model.predict(X_test)\n",
    "    \n",
    "    #Print test performance of the model\n",
    "    print()\n",
    "    print('Model Performance')\n",
    "    print(classification_report(y_test, best_model_predictions))\n",
    "    print(confusion_matrix(y_test, best_model_predictions))\n",
    "    \n",
    "    #print ('The score in CV for the best estimator:', search.best_score_)\n",
    "    #print ('The score in testing for the best estimator:', pred_function(best_model, X_train, y_train, X_test, y_test))\n",
    "    #print ('Accurary Score on testing set:', accuracy_score(best_model.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "rf_tune = { \n",
    "    'algorithm__n_estimators': [100,200, 300, 400, 500, 1000],\n",
    "    'algorithm__max_depth' : [4,5,6,7,8,9,10],\n",
    "    'algorithm__bootstrap': [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.016178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>0.020204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.031298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>0.069531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>0.018813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.041145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>0.018878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.024805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.031730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>0.021885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.019917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.027699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.026616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.114664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.048011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>0.036903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.017663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.051068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>0.020630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>0.027650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.023470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.020055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.023349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.018175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at sample</th>\n",
       "      <td>0.227921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.001741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Importance\n",
       "GP1              0.016178\n",
       "GP2              0.020204\n",
       "GP3              0.031298\n",
       "GP4              0.069531\n",
       "GP5              0.018813\n",
       "GP6              0.041145\n",
       "GP7              0.018878\n",
       "GP8              0.024805\n",
       "GP9              0.031730\n",
       "GP10             0.021885\n",
       "GP11             0.019917\n",
       "GP12             0.027699\n",
       "GP13             0.026616\n",
       "GP14             0.114664\n",
       "GP15             0.048011\n",
       "GP16             0.036903\n",
       "GP17             0.017663\n",
       "GP18             0.051068\n",
       "GP19             0.020630\n",
       "GP20             0.027650\n",
       "GP21             0.023470\n",
       "GP22             0.020055\n",
       "GP23             0.023349\n",
       "GP24             0.018175\n",
       "Age at sample    0.227921\n",
       "Gender           0.001741"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_rf, search_rf = grid_function(rf, rf_tune, X_train, y_train)\n",
    "rf_ranking = pd.DataFrame(best_model_rf._final_estimator.feature_importances_, index=X_train.columns)\n",
    "rf_ranking.columns = ['Importance']\n",
    "rf_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=7, n_estimators=300, random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.82      0.88      0.85       426\n",
      "     Control       0.61      0.48      0.54       162\n",
      "\n",
      "    accuracy                           0.77       588\n",
      "   macro avg       0.71      0.68      0.69       588\n",
      "weighted avg       0.76      0.77      0.76       588\n",
      "\n",
      "[[376  50]\n",
      " [ 84  78]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(rf, rf_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paramters\n",
    "svm_tune = { \n",
    "    'algorithm__kernel': ['linear'], \n",
    "    'algorithm__degree' : [2,3,4],\n",
    "    'algorithm__C':[0, 1.0],\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.77501404 0.77501404 0.77501404]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(degree=2, kernel='linear', random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.81      0.87      0.84       426\n",
      "     Control       0.58      0.47      0.52       162\n",
      "\n",
      "    accuracy                           0.76       588\n",
      "   macro avg       0.70      0.67      0.68       588\n",
      "weighted avg       0.75      0.76      0.75       588\n",
      "\n",
      "[[371  55]\n",
      " [ 86  76]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(svm, svm_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.77501404 0.77501404 0.77501404]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.334059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>-0.121222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>-0.105627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>-0.368241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>-0.153284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.598340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>-0.404958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.143984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.587813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>-0.347148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.114852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.340915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.378323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>-0.160649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.477219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>-0.645842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.061451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.330603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>-0.225141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>-0.363505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.045643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.046897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.276478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.341114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at sample</th>\n",
       "      <td>-0.495283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.124153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Importance\n",
       "GP1              0.334059\n",
       "GP2             -0.121222\n",
       "GP3             -0.105627\n",
       "GP4             -0.368241\n",
       "GP5             -0.153284\n",
       "GP6              0.598340\n",
       "GP7             -0.404958\n",
       "GP8              0.143984\n",
       "GP9              0.587813\n",
       "GP10            -0.347148\n",
       "GP11             0.114852\n",
       "GP12             0.340915\n",
       "GP13             0.378323\n",
       "GP14            -0.160649\n",
       "GP15             0.477219\n",
       "GP16            -0.645842\n",
       "GP17             0.061451\n",
       "GP18             0.330603\n",
       "GP19            -0.225141\n",
       "GP20            -0.363505\n",
       "GP21             0.045643\n",
       "GP22             0.046897\n",
       "GP23             0.276478\n",
       "GP24             0.341114\n",
       "Age at sample   -0.495283\n",
       "Gender           0.124153"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_svm, search_svm = grid_function(svm, svm_tune, X_train, y_train)\n",
    "\n",
    "svm_ranking = best_model_svm._final_estimator.coef_[0]\n",
    "\n",
    "svm_ranking_table = pd.DataFrame(svm_ranking, index=X_train.columns)\n",
    "svm_ranking_table.columns = ['Importance']\n",
    "svm_ranking_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "xgb_tune = { \n",
    "    'algorithm__eta': [0.01, 0.05, 0.1, 0.3, 0.5, 1], #Step size shrinkage used in update to prevents overfitting\n",
    "    'algorithm__max_depth' : [4,5,6,7,8,9,10],\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:42:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.026793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>0.023544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.038790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>0.047205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>0.023087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.021347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>0.022705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.025787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.023368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>0.022930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.030623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.037873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.037993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.126403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.048160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>0.030167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.019595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.042079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>0.031588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>0.025093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.032172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.030359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.022687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.034264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at sample</th>\n",
       "      <td>0.151840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.023545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Importance\n",
       "GP1              0.026793\n",
       "GP2              0.023544\n",
       "GP3              0.038790\n",
       "GP4              0.047205\n",
       "GP5              0.023087\n",
       "GP6              0.021347\n",
       "GP7              0.022705\n",
       "GP8              0.025787\n",
       "GP9              0.023368\n",
       "GP10             0.022930\n",
       "GP11             0.030623\n",
       "GP12             0.037873\n",
       "GP13             0.037993\n",
       "GP14             0.126403\n",
       "GP15             0.048160\n",
       "GP16             0.030167\n",
       "GP17             0.019595\n",
       "GP18             0.042079\n",
       "GP19             0.031588\n",
       "GP20             0.025093\n",
       "GP21             0.032172\n",
       "GP22             0.030359\n",
       "GP23             0.022687\n",
       "GP24             0.034264\n",
       "Age at sample    0.151840\n",
       "Gender           0.023545"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_xgb, search_xgb = grid_function(xgb, xgb_tune, X_train, y_train)\n",
    "xgb_ranking = pd.DataFrame(best_model_xgb._final_estimator.feature_importances_, index=X_train.columns)\n",
    "xgb_ranking.columns = ['Importance']\n",
    "xgb_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:44:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eta=0.05, gamma=0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.0500000007, max_delta_step=0, max_depth=4,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.83      0.85      0.84       426\n",
      "     Control       0.58      0.54      0.56       162\n",
      "\n",
      "    accuracy                           0.77       588\n",
      "   macro avg       0.71      0.70      0.70       588\n",
      "weighted avg       0.76      0.77      0.76       588\n",
      "\n",
      "[[363  63]\n",
      " [ 74  88]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(xgb, xgb_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To solve data imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Bagging Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "bbc_tune = { \n",
    "    'algorithm__n_estimators': [100,200, 300, 400, 500, 1000],\n",
    "    'algorithm__bootstrap': [True, False]\n",
    "    #'algorithm__base_estimator':['HistGradientBoostingClassifier', 'DeicisionTreeClassifier']\n",
    "}\n",
    "\n",
    "bbc = BalancedBaggingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedBaggingClassifier(n_estimators=400, random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.89      0.73      0.80       426\n",
      "     Control       0.52      0.76      0.61       162\n",
      "\n",
      "    accuracy                           0.74       588\n",
      "   macro avg       0.70      0.74      0.71       588\n",
      "weighted avg       0.79      0.74      0.75       588\n",
      "\n",
      "[[311 115]\n",
      " [ 39 123]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(bbc, bbc_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "brf_tune = { \n",
    "    'algorithm__n_estimators': [100,200, 300, 400, 500, 1000],\n",
    "    'algorithm__bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "brf = BalancedRandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedRandomForestClassifier(bootstrap=False, random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.93      0.70      0.80       426\n",
      "     Control       0.52      0.86      0.65       162\n",
      "\n",
      "    accuracy                           0.74       588\n",
      "   macro avg       0.72      0.78      0.72       588\n",
      "weighted avg       0.82      0.74      0.75       588\n",
      "\n",
      "[[297 129]\n",
      " [ 23 139]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(brf, brf_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "eec_tune = { \n",
    "    'algorithm__n_estimators': [100,200, 300]\n",
    "}\n",
    "\n",
    "eec = EasyEnsembleClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EasyEnsembleClassifier(n_estimators=300, random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.93      0.67      0.78       426\n",
      "     Control       0.50      0.88      0.64       162\n",
      "\n",
      "    accuracy                           0.73       588\n",
      "   macro avg       0.72      0.77      0.71       588\n",
      "weighted avg       0.82      0.73      0.74       588\n",
      "\n",
      "[[286 140]\n",
      " [ 20 142]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(eec, eec_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forrest Classifier with adjusted class weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "rf_balanced_tune = { \n",
    "    'algorithm__n_estimators': [100,200, 300, 400, 500, 1000],\n",
    "    'algorithm__max_depth' : [4,5,6,7,8,9,10],\n",
    "    'algorithm__bootstrap': [True]\n",
    "}\n",
    "\n",
    "rf_balanced = RandomForestClassifier(random_state=0, class_weight = 'balanced')\n",
    "rf_subsample_balanced = RandomForestClassifier(random_state=0, class_weight = 'balanced_subsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=1000,\n",
      "                       random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.84      0.83      0.83       426\n",
      "     Control       0.56      0.58      0.57       162\n",
      "\n",
      "    accuracy                           0.76       588\n",
      "   macro avg       0.70      0.70      0.70       588\n",
      "weighted avg       0.76      0.76      0.76       588\n",
      "\n",
      "[[353  73]\n",
      " [ 68  94]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(rf_balanced, rf_balanced_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
      "                       random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.85      0.83      0.84       426\n",
      "     Control       0.58      0.62      0.60       162\n",
      "\n",
      "    accuracy                           0.77       588\n",
      "   macro avg       0.72      0.72      0.72       588\n",
      "weighted avg       0.78      0.77      0.77       588\n",
      "\n",
      "[[354  72]\n",
      " [ 62 100]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(rf_subsample_balanced, rf_balanced_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
