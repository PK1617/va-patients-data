{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 108,
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
<<<<<<< HEAD
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "\n",
    "from xgboost import XGBClassifier\n"
=======
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model"
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 59,
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Cleaned_Dataframe.xlsx')\n",
    "df.set_index('Sample',inplace=True)\n",
    "\n",
    "#chnging type of data to 'category' from 'object'\n",
    "df.Gender = df.Gender.astype('category')\n",
    "df.Status = df.Status.astype('category')\n",
    "\n",
    "#separate cancer markers and input data\n",
    "df_outputs= df['Status']\n",
    "df_inputs = df.drop('Status',axis=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 60,
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_inputs, df_outputs, random_state=100, stratify=df_outputs, test_size=0.3)\\"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 61,
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_function(model, parameters, X_train, y_train):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "    \n",
    "    pipeline = Pipeline(steps=[('preprosessor', preprocessor),\n",
    "                               ('algorithm', model)])\n",
    "    \n",
    "    search = GridSearchCV(pipeline, parameters, cv=StratifiedKFold(5), n_jobs=-1)\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    return(best_model, search)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 122,
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_function(best_model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "\n",
    "    X_train_sc = preprocessor.fit_transform(X_train)\n",
    "    X_test_sc = preprocessor.transform(X_test)\n",
    "    \n",
    "    best_model._final_estimator.fit(X_train_sc, y_train)\n",
    "    \n",
    "    y_pred = best_model._final_estimator.predict(X_test_sc)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    #incorporate confusion matrix\n",
    "    \n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, tune_parameters, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    #Finding the best parameters \n",
    "    best_model, search = grid_function(model, tune_parameters, X_train, y_train)\n",
    "    print (best_model._final_estimator)\n",
    "   \n",
    "    #Calculate the labels for the test set\n",
    "    best_model_predictions = best_model.predict(X_test)\n",
    "    \n",
    "    #Print test performance of the model\n",
    "    print()\n",
    "    print('Model Performance')\n",
    "    print(classification_report(y_test, best_model_predictions))\n",
    "    print(confusion_matrix(y_test, best_model_predictions))\n",
    "    \n",
    "    #print ('The score in CV for the best estimator:', search.best_score_)\n",
    "    #print ('The score in testing for the best estimator:', pred_function(best_model, X_train, y_train, X_test, y_test))\n",
=======
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(model, tune_parameters, X_train, y_train):\n",
    "    \n",
    "    best_model, search = grid_function(model, tune_parameters, X_train, y_train)\n",
    "    \n",
    "    print (best_model._final_estimator) \n",
    "    print ('The score in CV for the best estimator:', search.best_score_)\n",
    "    print ('The score in testing for the best estimator:', pred_function(best_model, X_train, y_train, X_test, y_test))\n",
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
    "    #print ('Accurary Score on testing set:', accuracy_score(best_model.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "rf_tune = { \n",
    "    'algorithm__n_estimators': [100,200, 300, 400, 500, 1000],\n",
    "    'algorithm__max_depth' : [4,5,6,7,8,9,10],\n",
    "    'algorithm__bootstrap': [True]\n",
=======
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters\n",
    "rf_tune = { \n",
    "    'algorithm__n_estimators': [200, 500],\n",
    "    'algorithm__max_depth' : [4,5,6,7,8]\n",
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=5, n_estimators=500, random_state=0)\n",
      "The score in CV for the best estimator: 0.7841141340411413\n",
      "The score in testing for the best estimator: 0.7670068027210885\n",
      "Accurary Score on testing set: 0.7670068027210885\n"
     ]
    }
   ],
   "source": [
    "output(rf, rf_tune, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
<<<<<<< HEAD
       "      <td>0.016178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>0.020204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.031298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>0.069531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>0.018813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.041145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>0.018878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.024805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.031730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>0.021885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.019917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.027699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.026616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.114664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.048011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>0.036903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.017663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.051068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>0.020630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>0.027650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.023470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.020055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.023349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.018175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at sample</th>\n",
       "      <td>0.227921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.001741</td>\n",
=======
       "      <td>0.015351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>0.014911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.027179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>0.085093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>0.013145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.038484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>0.012390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.015803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.030703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>0.014478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.013807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.030467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.025642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.134336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>0.025234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.011686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.057436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>0.013919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>0.019678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.017137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.015172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.010854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at sample</th>\n",
       "      <td>0.285149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.000500</td>\n",
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Importance\n",
<<<<<<< HEAD
       "GP1              0.016178\n",
       "GP2              0.020204\n",
       "GP3              0.031298\n",
       "GP4              0.069531\n",
       "GP5              0.018813\n",
       "GP6              0.041145\n",
       "GP7              0.018878\n",
       "GP8              0.024805\n",
       "GP9              0.031730\n",
       "GP10             0.021885\n",
       "GP11             0.019917\n",
       "GP12             0.027699\n",
       "GP13             0.026616\n",
       "GP14             0.114664\n",
       "GP15             0.048011\n",
       "GP16             0.036903\n",
       "GP17             0.017663\n",
       "GP18             0.051068\n",
       "GP19             0.020630\n",
       "GP20             0.027650\n",
       "GP21             0.023470\n",
       "GP22             0.020055\n",
       "GP23             0.023349\n",
       "GP24             0.018175\n",
       "Age at sample    0.227921\n",
       "Gender           0.001741"
      ]
     },
     "execution_count": 11,
=======
       "GP1              0.015351\n",
       "GP2              0.014911\n",
       "GP3              0.027179\n",
       "GP4              0.085093\n",
       "GP5              0.013145\n",
       "GP6              0.038484\n",
       "GP7              0.012390\n",
       "GP8              0.015803\n",
       "GP9              0.030703\n",
       "GP10             0.014478\n",
       "GP11             0.013807\n",
       "GP12             0.030467\n",
       "GP13             0.025642\n",
       "GP14             0.134336\n",
       "GP15             0.056818\n",
       "GP16             0.025234\n",
       "GP17             0.011686\n",
       "GP18             0.057436\n",
       "GP19             0.013919\n",
       "GP20             0.019678\n",
       "GP21             0.017137\n",
       "GP22             0.014629\n",
       "GP23             0.015172\n",
       "GP24             0.010854\n",
       "Age at sample    0.285149\n",
       "Gender           0.000500"
      ]
     },
     "execution_count": 119,
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "#To extract feature importance scores \n",
    "best_model_rf, search_rf = grid_function(rf, rf_tune, X_train, y_train)\n",
    "rf_ranking = pd.DataFrame(best_model_rf._final_estimator.feature_importances_, index=X_train.columns)\n",
=======
    "best_model_rf, search_rf = grid_function(rf, rf_tune, X_train, y_train)\n",
    "rf_ranking = pd.DataFrame(best_model_rf._final_estimator.feature_importances_, index=X_val.columns)\n",
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
    "rf_ranking.columns = ['Importance']\n",
    "rf_ranking"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=7, n_estimators=300, random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.82      0.88      0.85       426\n",
      "     Control       0.61      0.48      0.54       162\n",
      "\n",
      "    accuracy                           0.77       588\n",
      "   macro avg       0.71      0.68      0.69       588\n",
      "weighted avg       0.76      0.77      0.76       588\n",
      "\n",
      "[[376  50]\n",
      " [ 84  78]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(rf, rf_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (not complete) SVM"
=======
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "#Define paramters\n",
=======
    "#define paramters\n",
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
    "svm_tune = { \n",
    "    'algorithm__kernel': ['linear', 'rbf','poly','sigmoid'],\n",
    "    'algorithm__degree' : [2,3,4],\n",
    "    'algorithm__C':[0, 1.0],\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(degree=2, random_state=0)\n",
      "The score in CV for the best estimator: 0.7680769741207698\n",
      "The score in testing for the best estimator: 0.7687074829931972\n",
      "Accurary Score on testing set: 0.7687074829931972\n"
     ]
    }
   ],
   "source": [
    "output(svm, svm_tune, X_train, y_train)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "xgb_tune = { \n",
    "    'algorithm__eta': [0.01, 0.05, 0.1, 0.3, 0.5, 1], #Step size shrinkage used in update to prevents overfitting\n",
    "    'algorithm__max_depth' : [4,5,6,7,8,9,10],\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:42:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.026793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>0.023544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.038790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>0.047205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>0.023087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.021347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>0.022705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.025787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.023368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>0.022930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.030623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.037873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.037993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.126403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.048160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>0.030167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.019595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.042079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>0.031588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>0.025093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.032172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.030359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.022687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.034264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age at sample</th>\n",
       "      <td>0.151840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.023545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Importance\n",
       "GP1              0.026793\n",
       "GP2              0.023544\n",
       "GP3              0.038790\n",
       "GP4              0.047205\n",
       "GP5              0.023087\n",
       "GP6              0.021347\n",
       "GP7              0.022705\n",
       "GP8              0.025787\n",
       "GP9              0.023368\n",
       "GP10             0.022930\n",
       "GP11             0.030623\n",
       "GP12             0.037873\n",
       "GP13             0.037993\n",
       "GP14             0.126403\n",
       "GP15             0.048160\n",
       "GP16             0.030167\n",
       "GP17             0.019595\n",
       "GP18             0.042079\n",
       "GP19             0.031588\n",
       "GP20             0.025093\n",
       "GP21             0.032172\n",
       "GP22             0.030359\n",
       "GP23             0.022687\n",
       "GP24             0.034264\n",
       "Age at sample    0.151840\n",
       "Gender           0.023545"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_xgb, search_xgb = grid_function(xgb, xgb_tune, X_train, y_train)\n",
    "xgb_ranking = pd.DataFrame(best_model_xgb._final_estimator.feature_importances_, index=X_train.columns)\n",
    "xgb_ranking.columns = ['Importance']\n",
    "xgb_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:44:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eta=0.05, gamma=0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.0500000007, max_delta_step=0, max_depth=4,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.83      0.85      0.84       426\n",
      "     Control       0.58      0.54      0.56       162\n",
      "\n",
      "    accuracy                           0.77       588\n",
      "   macro avg       0.71      0.70      0.70       588\n",
      "weighted avg       0.76      0.77      0.76       588\n",
      "\n",
      "[[363  63]\n",
      " [ 74  88]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(xgb, xgb_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
=======
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.12"
=======
   "version": "3.8.5"
>>>>>>> 777ab50a5fa62f7ccae8b95bfaadeac169c7483a
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
