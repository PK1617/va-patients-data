{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  \n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, EasyEnsembleClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler # to check again how to use this in a pipeline \n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP1</th>\n",
       "      <th>GP2</th>\n",
       "      <th>GP3</th>\n",
       "      <th>GP4</th>\n",
       "      <th>GP5</th>\n",
       "      <th>GP6</th>\n",
       "      <th>GP7</th>\n",
       "      <th>GP8</th>\n",
       "      <th>GP9</th>\n",
       "      <th>GP10</th>\n",
       "      <th>...</th>\n",
       "      <th>GP18</th>\n",
       "      <th>GP19</th>\n",
       "      <th>GP20</th>\n",
       "      <th>GP21</th>\n",
       "      <th>GP22</th>\n",
       "      <th>GP23</th>\n",
       "      <th>GP24</th>\n",
       "      <th>Age at sample</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRC_2894</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.66</td>\n",
       "      <td>26.79</td>\n",
       "      <td>0.42</td>\n",
       "      <td>5.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.76</td>\n",
       "      <td>12.22</td>\n",
       "      <td>5.27</td>\n",
       "      <td>...</td>\n",
       "      <td>6.09</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.02</td>\n",
       "      <td>55.142466</td>\n",
       "      <td>M</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_4054</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.67</td>\n",
       "      <td>28.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.42</td>\n",
       "      <td>16.55</td>\n",
       "      <td>11.04</td>\n",
       "      <td>3.94</td>\n",
       "      <td>...</td>\n",
       "      <td>6.70</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.15</td>\n",
       "      <td>69.594521</td>\n",
       "      <td>M</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_2686</th>\n",
       "      <td>0.34</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.73</td>\n",
       "      <td>21.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>19.37</td>\n",
       "      <td>11.84</td>\n",
       "      <td>4.51</td>\n",
       "      <td>...</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.44</td>\n",
       "      <td>44.824658</td>\n",
       "      <td>F</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_3848</th>\n",
       "      <td>0.20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.49</td>\n",
       "      <td>26.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8.06</td>\n",
       "      <td>1.28</td>\n",
       "      <td>16.01</td>\n",
       "      <td>10.48</td>\n",
       "      <td>5.45</td>\n",
       "      <td>...</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.62</td>\n",
       "      <td>74.728767</td>\n",
       "      <td>F</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_7633</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>26.87</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>16.90</td>\n",
       "      <td>9.34</td>\n",
       "      <td>6.68</td>\n",
       "      <td>...</td>\n",
       "      <td>6.18</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "      <td>54.876712</td>\n",
       "      <td>M</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_9725</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>20.33</td>\n",
       "      <td>0.63</td>\n",
       "      <td>5.62</td>\n",
       "      <td>1.28</td>\n",
       "      <td>18.64</td>\n",
       "      <td>12.78</td>\n",
       "      <td>5.36</td>\n",
       "      <td>...</td>\n",
       "      <td>7.14</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.27</td>\n",
       "      <td>51.380822</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_9763</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>6.19</td>\n",
       "      <td>0.76</td>\n",
       "      <td>18.78</td>\n",
       "      <td>7.92</td>\n",
       "      <td>5.31</td>\n",
       "      <td>...</td>\n",
       "      <td>9.78</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.87</td>\n",
       "      <td>47.915068</td>\n",
       "      <td>F</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_9765</th>\n",
       "      <td>0.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.83</td>\n",
       "      <td>17.04</td>\n",
       "      <td>0.56</td>\n",
       "      <td>5.39</td>\n",
       "      <td>1.60</td>\n",
       "      <td>20.71</td>\n",
       "      <td>10.02</td>\n",
       "      <td>6.81</td>\n",
       "      <td>...</td>\n",
       "      <td>8.63</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.72</td>\n",
       "      <td>47.479452</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_9784</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.32</td>\n",
       "      <td>22.14</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.93</td>\n",
       "      <td>18.52</td>\n",
       "      <td>15.42</td>\n",
       "      <td>4.29</td>\n",
       "      <td>...</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.05</td>\n",
       "      <td>50.323288</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC_9835</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.41</td>\n",
       "      <td>31.84</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>17.16</td>\n",
       "      <td>8.96</td>\n",
       "      <td>5.41</td>\n",
       "      <td>...</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.80</td>\n",
       "      <td>55.027397</td>\n",
       "      <td>M</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1076 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GP1   GP2   GP3    GP4   GP5   GP6   GP7    GP8    GP9  GP10  ...  \\\n",
       "Sample                                                                   ...   \n",
       "CRC_2894  0.96  0.73  0.66  26.79  0.42  5.78  0.75  18.76  12.22  5.27  ...   \n",
       "CRC_4054  0.27  0.49  0.67  28.69  0.57  4.84  0.42  16.55  11.04  3.94  ...   \n",
       "CRC_2686  0.34  1.04  0.73  21.36  0.36  4.08  0.58  19.37  11.84  4.51  ...   \n",
       "CRC_3848  0.20  1.35  0.49  26.83  0.51  8.06  1.28  16.01  10.48  5.45  ...   \n",
       "CRC_7633  0.14  0.76  0.74  26.87  0.64  9.05  0.95  16.90   9.34  6.68  ...   \n",
       "...        ...   ...   ...    ...   ...   ...   ...    ...    ...   ...  ...   \n",
       "CRC_9725  0.13  0.92  0.68  20.33  0.63  5.62  1.28  18.64  12.78  5.36  ...   \n",
       "CRC_9763  0.04  0.54  0.42  21.59  0.35  6.19  0.76  18.78   7.92  5.31  ...   \n",
       "CRC_9765  0.13  1.10  0.83  17.04  0.56  5.39  1.60  20.71  10.02  6.81  ...   \n",
       "CRC_9784  0.08  0.80  0.32  22.14  0.35  4.67  0.93  18.52  15.42  4.29  ...   \n",
       "CRC_9835  0.15  0.46  0.41  31.84  0.32  7.39  0.46  17.16   8.96  5.41  ...   \n",
       "\n",
       "          GP18  GP19  GP20  GP21  GP22  GP23  GP24  Age at sample  Gender  \\\n",
       "Sample                                                                      \n",
       "CRC_2894  6.09  1.59  0.39  0.86  0.10  0.98  1.02      55.142466       M   \n",
       "CRC_4054  6.70  2.25  0.68  1.29  0.24  1.99  2.15      69.594521       M   \n",
       "CRC_2686  8.67  1.92  0.38  1.89  0.29  1.52  1.44      44.824658       F   \n",
       "CRC_3848  5.80  1.72  0.40  1.33  0.44  1.11  1.62      74.728767       F   \n",
       "CRC_7633  6.18  1.68  0.77  0.93  0.17  0.69  1.00      54.876712       M   \n",
       "...        ...   ...   ...   ...   ...   ...   ...            ...     ...   \n",
       "CRC_9725  7.14  1.72  0.22  0.93  0.11  1.05  1.27      51.380822       M   \n",
       "CRC_9763  9.78  1.61  0.33  0.42  0.14  0.53  0.87      47.915068       F   \n",
       "CRC_9765  8.63  2.03  0.43  0.46  0.29  1.06  1.72      47.479452       M   \n",
       "CRC_9784  6.72  1.45  0.34  0.65  0.09  0.97  1.05      50.323288       M   \n",
       "CRC_9835  5.80  2.21  0.35  0.70  0.09  1.09  1.80      55.027397       M   \n",
       "\n",
       "           Status  \n",
       "Sample             \n",
       "CRC_2894   Cancer  \n",
       "CRC_4054   Cancer  \n",
       "CRC_2686   Cancer  \n",
       "CRC_3848   Cancer  \n",
       "CRC_7633   Cancer  \n",
       "...           ...  \n",
       "CRC_9725  Control  \n",
       "CRC_9763  Control  \n",
       "CRC_9765  Control  \n",
       "CRC_9784  Control  \n",
       "CRC_9835  Control  \n",
       "\n",
       "[1076 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Cleaned_Dataframe.xlsx')\n",
    "df.set_index('Sample',inplace=True)\n",
    "\n",
    "df_cancer = df.loc[df['Status'] == 'Cancer']\n",
    "df_control = df.loc[df['Status'] == 'Control']\n",
    "\n",
    "#randomly seelct 538 samples from the cancer population to create an equal sample size\n",
    "df_cancer_small = df_cancer.sample(n=538)\n",
    "\n",
    "df1 = pd.concat([df_cancer_small, df_control])\n",
    "df1                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chnging type of data to 'category' from 'object'\n",
    "df1.Gender = df1.Gender.astype('category')\n",
    "df1.Status = df1.Status.astype('category')\n",
    "\n",
    "#separate cancer markers and input data\n",
    "df1_outputs= df1['Status']\n",
    "df1_inputs = df1.drop(['Status', 'Age at sample'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1_inputs, df1_outputs, random_state=100, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_function(model, parameters, X_train, y_train):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(steps=[('preprosessor', preprocessor), ('algorithm', model)])\n",
    "                        #RandomUnderSampler(random_state = 42))\n",
    "    \n",
    "    search = GridSearchCV(pipeline, parameters, cv=StratifiedKFold(5), n_jobs=-1)\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    return(best_model, search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_function(model, tune_parameters, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "\n",
    "    X_train_sc = preprocessor.fit_transform(X_train)\n",
    "    X_test_sc = preprocessor.transform(X_test)\n",
    "    \n",
    "    #Finding the best parameters \n",
    "    best_model, search = grid_function(model, tune_parameters, X_train, y_train)\n",
    "    print (best_model._final_estimator)\n",
    "    \n",
    "    #Make prediction using the best model\n",
    "    best_model._final_estimator.fit(X_train_sc, y_train)\n",
    "    y_pred = best_model._final_estimator.predict(X_test_sc)\n",
    "\n",
    "    #Print test performance of the model\n",
    "    print()\n",
    "    print('Model Performance')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "rf_tune = { \n",
    "    'algorithm__n_estimators': [100,200, 300, 400, 500, 1000],\n",
    "    'algorithm__max_depth' : [4,5,6,7,8,9,10],\n",
    "    'algorithm__bootstrap': [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.031323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>0.028697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.031646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>0.076973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>0.040040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.040274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>0.030196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.030665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.048731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>0.028669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.028551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.033440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.030362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.132010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.049273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>0.032077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.027644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.067108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>0.027174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>0.039848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.055887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.031480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.026721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.027039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.004173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Importance\n",
       "GP1       0.031323\n",
       "GP2       0.028697\n",
       "GP3       0.031646\n",
       "GP4       0.076973\n",
       "GP5       0.040040\n",
       "GP6       0.040274\n",
       "GP7       0.030196\n",
       "GP8       0.030665\n",
       "GP9       0.048731\n",
       "GP10      0.028669\n",
       "GP11      0.028551\n",
       "GP12      0.033440\n",
       "GP13      0.030362\n",
       "GP14      0.132010\n",
       "GP15      0.049273\n",
       "GP16      0.032077\n",
       "GP17      0.027644\n",
       "GP18      0.067108\n",
       "GP19      0.027174\n",
       "GP20      0.039848\n",
       "GP21      0.055887\n",
       "GP22      0.031480\n",
       "GP23      0.026721\n",
       "GP24      0.027039\n",
       "Gender    0.004173"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_rf, search_rf = grid_function(rf, rf_tune, X_train, y_train)\n",
    "rf_ranking = pd.DataFrame(best_model_rf._final_estimator.feature_importances_, index=X_train.columns)\n",
    "rf_ranking.columns = ['Importance']\n",
    "rf_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=7, random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.74      0.63      0.68       170\n",
      "     Control       0.65      0.76      0.70       153\n",
      "\n",
      "    accuracy                           0.69       323\n",
      "   macro avg       0.70      0.69      0.69       323\n",
      "weighted avg       0.70      0.69      0.69       323\n",
      "\n",
      "[[107  63]\n",
      " [ 37 116]]\n"
     ]
    }
   ],
   "source": [
    "pred_function(rf, rf_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paramters\n",
    "svm_tune = { \n",
    "    'algorithm__kernel': ['linear'], \n",
    "    'algorithm__degree' : [2,3,4],\n",
    "    'algorithm__C':[0, 1.0],\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(degree=2, kernel='linear', random_state=0)\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.77      0.69      0.73       170\n",
      "     Control       0.69      0.77      0.73       153\n",
      "\n",
      "    accuracy                           0.73       323\n",
      "   macro avg       0.73      0.73      0.73       323\n",
      "weighted avg       0.73      0.73      0.73       323\n",
      "\n",
      "[[118  52]\n",
      " [ 35 118]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.72631347 0.72631347 0.72631347]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "pred_function(svm, svm_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.73700662 0.73700662 0.73700662]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.624631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>-0.342848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.143209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>-0.447163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>-0.212552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.771183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>-0.806407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.353247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.482703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>-0.804781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>-0.050644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.895136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.265048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.166826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>1.088392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>-0.113561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>-0.429172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>-0.190548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>-0.201901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>-0.557995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>-0.180470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.526968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.035072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.379814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>-0.023892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Importance\n",
       "GP1       0.624631\n",
       "GP2      -0.342848\n",
       "GP3       0.143209\n",
       "GP4      -0.447163\n",
       "GP5      -0.212552\n",
       "GP6       0.771183\n",
       "GP7      -0.806407\n",
       "GP8       0.353247\n",
       "GP9       0.482703\n",
       "GP10     -0.804781\n",
       "GP11     -0.050644\n",
       "GP12      0.895136\n",
       "GP13      0.265048\n",
       "GP14      0.166826\n",
       "GP15      1.088392\n",
       "GP16     -0.113561\n",
       "GP17     -0.429172\n",
       "GP18     -0.190548\n",
       "GP19     -0.201901\n",
       "GP20     -0.557995\n",
       "GP21     -0.180470\n",
       "GP22      0.526968\n",
       "GP23      0.035072\n",
       "GP24      0.379814\n",
       "Gender   -0.023892"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_svm, search_svm = grid_function(svm, svm_tune, X_train, y_train)\n",
    "\n",
    "svm_ranking = best_model_svm._final_estimator.coef_[0]\n",
    "\n",
    "svm_ranking_table = pd.DataFrame(svm_ranking, index=X_train.columns)\n",
    "svm_ranking_table.columns = ['Importance']\n",
    "svm_ranking_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "xgb_tune = { \n",
    "    'algorithm__eta': [0.01, 0.05, 0.1, 0.3, 0.5, 1], #Step size shrinkage used in update to prevents overfitting\n",
    "    'algorithm__max_depth' : [4,5,6,7,8,9,10],\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:00:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP1</th>\n",
       "      <td>0.037186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2</th>\n",
       "      <td>0.023617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP3</th>\n",
       "      <td>0.028669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP4</th>\n",
       "      <td>0.038457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP5</th>\n",
       "      <td>0.031117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP6</th>\n",
       "      <td>0.022952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP7</th>\n",
       "      <td>0.035371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>0.031611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP9</th>\n",
       "      <td>0.043042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP10</th>\n",
       "      <td>0.022348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP11</th>\n",
       "      <td>0.030019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP12</th>\n",
       "      <td>0.032862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP13</th>\n",
       "      <td>0.029967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>0.221450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP15</th>\n",
       "      <td>0.042681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP16</th>\n",
       "      <td>0.026318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP17</th>\n",
       "      <td>0.031990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>0.022020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP19</th>\n",
       "      <td>0.023027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP20</th>\n",
       "      <td>0.039366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP21</th>\n",
       "      <td>0.045537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>0.035329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP23</th>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP24</th>\n",
       "      <td>0.031617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.039150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Importance\n",
       "GP1       0.037186\n",
       "GP2       0.023617\n",
       "GP3       0.028669\n",
       "GP4       0.038457\n",
       "GP5       0.031117\n",
       "GP6       0.022952\n",
       "GP7       0.035371\n",
       "GP8       0.031611\n",
       "GP9       0.043042\n",
       "GP10      0.022348\n",
       "GP11      0.030019\n",
       "GP12      0.032862\n",
       "GP13      0.029967\n",
       "GP14      0.221450\n",
       "GP15      0.042681\n",
       "GP16      0.026318\n",
       "GP17      0.031990\n",
       "GP18      0.022020\n",
       "GP19      0.023027\n",
       "GP20      0.039366\n",
       "GP21      0.045537\n",
       "GP22      0.035329\n",
       "GP23      0.034300\n",
       "GP24      0.031617\n",
       "Gender    0.039150"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To extract feature importance scores \n",
    "best_model_xgb, search_xgb = grid_function(xgb, xgb_tune, X_train, y_train)\n",
    "xgb_ranking = pd.DataFrame(best_model_xgb._final_estimator.feature_importances_, index=X_train.columns)\n",
    "xgb_ranking.columns = ['Importance']\n",
    "xgb_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:39:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eta=0.3, gamma=0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "[16:39:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.72      0.68      0.70       170\n",
      "     Control       0.66      0.71      0.69       153\n",
      "\n",
      "    accuracy                           0.69       323\n",
      "   macro avg       0.69      0.69      0.69       323\n",
      "weighted avg       0.70      0.69      0.69       323\n",
      "\n",
      "[[115  55]\n",
      " [ 44 109]]\n"
     ]
    }
   ],
   "source": [
    "pred_function(xgb, xgb_tune, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=2, kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_svm._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_rf._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_evaluate(best_model_rf, best_model_svm, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(drop='if_binary', handle_unknown='error')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', cat_transformer, selector(dtype_include=\"category\"))])\n",
    "\n",
    "    X_train_sc = preprocessor.fit_transform(X_train)\n",
    "    X_test_sc = preprocessor.transform(X_test)\n",
    "    \n",
    "    estimators = [('rf', best_model_rf._final_estimator),\n",
    "                 ('svm', best_model_svm._final_estimator),\n",
    "                 ('xgb', best_model_xgb._final_estimator)]\n",
    "    \n",
    "    sc = StackingClassifier(estimators = estimators, \n",
    "                           final_estimator = LogisticRegression())\n",
    "    \n",
    "    sc.fit(X_train_sc, y_train)\n",
    "    \n",
    "    y_pred = sc.predict(X_test_sc)\n",
    "    \n",
    "    #Print test performance of the model\n",
    "    print()\n",
    "    print('Model Performance')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:33:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:33:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang-\\anaconda3\\envs\\FYP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Model Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.76      0.70      0.73       170\n",
      "     Control       0.69      0.76      0.72       153\n",
      "\n",
      "    accuracy                           0.73       323\n",
      "   macro avg       0.73      0.73      0.73       323\n",
      "weighted avg       0.73      0.73      0.73       323\n",
      "\n",
      "[[119  51]\n",
      " [ 37 116]]\n"
     ]
    }
   ],
   "source": [
    "pred_evaluate(best_model_rf, best_model_svm, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
