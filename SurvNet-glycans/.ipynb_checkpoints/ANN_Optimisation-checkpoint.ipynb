{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import  StandardScaler, LabelEncoder, OneHotEncoder, LabelBinarizer, MinMaxScaler\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Dropout, GaussianNoise, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data function for reading and processing the train and test sets\n",
    "#necessary as an input for the optimisation algorithm\n",
    "def data():\n",
    "    #define input processing function\n",
    "    def process_attributes(df, train, test):\n",
    "        \n",
    "        #define and fit the scaler to the full dataset\n",
    "        cs = MinMaxScaler()\n",
    "        cs.fit(df_inputs.select_dtypes(np.number))\n",
    "        \n",
    "        #scale the numerical input variables\n",
    "        trainContinuous = cs.transform(train.select_dtypes(np.number))\n",
    "        testContinuous = cs.transform(test.select_dtypes(np.number))\n",
    "        \n",
    "        #uncomment the code below to accommodate for any categorical columns\n",
    "        zipBinarizer = LabelBinarizer().fit(df[\"Gender\"])\n",
    "        trainCategorical = zipBinarizer.transform(train[\"Gender\"])\n",
    "        testCategorical = zipBinarizer.transform(test[\"Gender\"])\n",
    "        \n",
    "        # construct our training and testing data points by concatenating\n",
    "        # the categorical features with the continuous features\n",
    "        trainX = np.hstack([trainContinuous, trainCategorical])\n",
    "        testX = np.hstack([testContinuous, testCategorical])\n",
    "        \n",
    "        #return the processed train and test sets\n",
    "        #trainX=trainContinuous\n",
    "        #testX=testContinuous\n",
    "        \n",
    "        # return the concatenated training and testing data\n",
    "        return (trainX, testX)\n",
    "    \n",
    "    #read the excel datasets\n",
    "    df = pd.read_excel('Cleaned_Dataframe.xlsx')\n",
    "    df.set_index('Sample',inplace=True)\n",
    "    features=df.columns\n",
    "\n",
    "    #separate cancer markers and input data\n",
    "    df_outputs= df['Status']\n",
    "    df_inputs = df.drop('Status',axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_inputs, df_outputs, random_state=100, stratify=df_outputs, test_size=0.3)\n",
    "    \n",
    "    #process the input sets\n",
    "    (X_train_sc, X_test_sc) = process_attributes(df_inputs, X_train, X_test)\n",
    "    \n",
    "    #encode the categorical output variables\n",
    "    #encode categorical outputs\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    train_outputs= lb.transform(y_train)\n",
    "    test_outputs= lb.transform(y_test)\n",
    "\n",
    "    Y_train = tf.keras.utils.to_categorical(train_outputs)\n",
    "    Y_test = tf.keras.utils.to_categorical(test_outputs)\n",
    "\n",
    "    return X_train_sc, Y_train, X_test_sc, Y_test, lb, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model and search space for the optimisation algorithm\n",
    "def model(X_train_sc, Y_train, X_test_sc, Y_test):\n",
    "    \n",
    "    #define ANN model and search space\n",
    "    def ANN():\n",
    "        \n",
    "        #define first two layers, possible alternatives for neurons in each,\n",
    "        #activation function, and dropout layers\n",
    "        model=Sequential()\n",
    "        Dropout_rate={{uniform(0, 0.3)}}\n",
    "        model.add(Dense({{choice([8,16, 24, 32, 64])}}))\n",
    "        model.add(Activation({{choice(['relu', 'sigmoid', 'tanh'])}}))\n",
    "\n",
    "        model.add(Dropout(Dropout_rate))\n",
    "\n",
    "        model.add(Dense({{choice([8,16, 24, 32, 64])}}))\n",
    "        model.add(Activation({{choice(['relu', 'sigmoid', 'tanh'])}}))\n",
    "\n",
    "        model.add(Dropout(Dropout_rate))\n",
    "        \n",
    "        #define output layer of the model\n",
    "        \n",
    "        model.add(Dense(2))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        #define optimisation algorithm for network training\n",
    "        optim=tf.keras.optimizers.Adam(learning_rate={{choice([0.005, 0.001, 0.0001])}})\n",
    "        \n",
    "        #compile model and return it\n",
    "        model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
    "        \n",
    "        return model \n",
    "    \n",
    "    #encode and transform labels for model training\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(np.argmax(Y_train,axis=1))\n",
    "    \n",
    "    #call the ANN and ddefine training epochs; define batch size alternatives\n",
    "    net = KerasClassifier(build_fn = ANN,\n",
    "                                 epochs={{choice([50,100,200])}},\n",
    "                                 batch_size= {{choice([32,64])}},\n",
    "                                 verbose = 0)\n",
    "    model = ANN()\n",
    "    \n",
    "    #set up cross-validation scoring, and returned variables\n",
    "    c = cross_val_score(net,\n",
    "                    X_train_sc, y,\n",
    "                    cv= StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                    scoring='accuracy').mean()\n",
    "    print('Test accuracy:', c)\n",
    "    return {'loss': -c, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call in data function for test evaluation later\n",
    "X_train, Y_train, X_test, Y_test, lb, features = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.pipeline import Pipeline\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, cross_val_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, LabelBinarizer, MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.compose import make_column_selector as selector\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.compose import ColumnTransformer\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, LSTM, SimpleRNN, Dropout, GaussianNoise, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam, SGD\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.utils import to_categorical\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.wrappers.scikit_learn import KerasClassifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout_rate': hp.uniform('Dropout_rate', 0, 0.3),\n",
      "        'Dense': hp.choice('Dense', [8,16, 24, 32, 64]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid', 'tanh']),\n",
      "        'Dense_1': hp.choice('Dense_1', [8,16, 24, 32, 64]),\n",
      "        'Activation_1': hp.choice('Activation_1', ['relu', 'sigmoid', 'tanh']),\n",
      "        'learning_rate': hp.choice('learning_rate', [0.005, 0.001, 0.0001]),\n",
      "        'epochs': hp.choice('epochs', [50,100,200]),\n",
      "        'batch_size': hp.choice('batch_size', [32,64]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: #define input processing function\n",
      "   3: def process_attributes(df, train, test):\n",
      "   4:     \n",
      "   5:     #define and fit the scaler to the full dataset\n",
      "   6:     cs = MinMaxScaler()\n",
      "   7:     cs.fit(df_inputs.select_dtypes(np.number))\n",
      "   8:     \n",
      "   9:     #scale the numerical input variables\n",
      "  10:     trainContinuous = cs.transform(train.select_dtypes(np.number))\n",
      "  11:     testContinuous = cs.transform(test.select_dtypes(np.number))\n",
      "  12:     \n",
      "  13:     #uncomment the code below to accommodate for any categorical columns\n",
      "  14:     zipBinarizer = LabelBinarizer().fit(df[\"Gender\"])\n",
      "  15:     trainCategorical = zipBinarizer.transform(train[\"Gender\"])\n",
      "  16:     testCategorical = zipBinarizer.transform(test[\"Gender\"])\n",
      "  17:     \n",
      "  18:     # construct our training and testing data points by concatenating\n",
      "  19:     # the categorical features with the continuous features\n",
      "  20:     trainX = np.hstack([trainContinuous, trainCategorical])\n",
      "  21:     testX = np.hstack([testContinuous, testCategorical])\n",
      "  22:     \n",
      "  23:     #return the processed train and test sets\n",
      "  24:     #trainX=trainContinuous\n",
      "  25:     #testX=testContinuous\n",
      "  26:     \n",
      "  27:     # return the concatenated training and testing data\n",
      "  28:     return (trainX, testX)\n",
      "  29: \n",
      "  30: #read the excel datasets\n",
      "  31: df = pd.read_excel('Cleaned_Dataframe.xlsx')\n",
      "  32: df.set_index('Sample',inplace=True)\n",
      "  33: features=df.columns\n",
      "  34: \n",
      "  35: #separate cancer markers and input data\n",
      "  36: df_outputs= df['Status']\n",
      "  37: df_inputs = df.drop('Status',axis=1)\n",
      "  38: \n",
      "  39: X_train, X_test, y_train, y_test = train_test_split(df_inputs, df_outputs, random_state=100, stratify=df_outputs, test_size=0.3)\n",
      "  40: \n",
      "  41: #process the input sets\n",
      "  42: (X_train_sc, X_test_sc) = process_attributes(df_inputs, X_train, X_test)\n",
      "  43: \n",
      "  44: #encode the categorical output variables\n",
      "  45: #encode categorical outputs\n",
      "  46: lb = LabelBinarizer()\n",
      "  47: lb.fit(y_train)\n",
      "  48: train_outputs= lb.transform(y_train)\n",
      "  49: test_outputs= lb.transform(y_test)\n",
      "  50: \n",
      "  51: Y_train = tf.keras.utils.to_categorical(train_outputs)\n",
      "  52: Y_test = tf.keras.utils.to_categorical(test_outputs)\n",
      "  53: \n",
      "  54: \n",
      "  55: \n",
      "  56: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     #define ANN model and search space\n",
      "   5:     def ANN():\n",
      "   6:         \n",
      "   7:         #define first two layers, possible alternatives for neurons in each,\n",
      "   8:         #activation function, and dropout layers\n",
      "   9:         model=Sequential()\n",
      "  10:         Dropout_rate=space['Dropout_rate']\n",
      "  11:         model.add(Dense(space['Dense']))\n",
      "  12:         model.add(Activation(space['Activation']))\n",
      "  13: \n",
      "  14:         model.add(Dropout(Dropout_rate))\n",
      "  15: \n",
      "  16:         model.add(Dense(space['Dense_1']))\n",
      "  17:         model.add(Activation(space['Activation_1']))\n",
      "  18: \n",
      "  19:         model.add(Dropout(Dropout_rate))\n",
      "  20:         \n",
      "  21:         #define output layer of the model\n",
      "  22:         \n",
      "  23:         model.add(Dense(2))\n",
      "  24:         model.add(Activation('softmax'))\n",
      "  25:         \n",
      "  26:         #define optimisation algorithm for network training\n",
      "  27:         optim=tf.keras.optimizers.Adam(learning_rate=space['learning_rate'])\n",
      "  28:         \n",
      "  29:         #compile model and return it\n",
      "  30:         model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
      "  31:         \n",
      "  32:         return model \n",
      "  33:     \n",
      "  34:     #encode and transform labels for model training\n",
      "  35:     label_encoder = LabelEncoder()\n",
      "  36:     y = label_encoder.fit_transform(np.argmax(Y_train,axis=1))\n",
      "  37:     \n",
      "  38:     #call the ANN and ddefine training epochs; define batch size alternatives\n",
      "  39:     net = KerasClassifier(build_fn = ANN,\n",
      "  40:                                  epochs=space['epochs'],\n",
      "  41:                                  batch_size= space['batch_size'],\n",
      "  42:                                  verbose = 0)\n",
      "  43:     model = ANN()\n",
      "  44:     \n",
      "  45:     #set up cross-validation scoring, and returned variables\n",
      "  46:     c = cross_val_score(net,\n",
      "  47:                     X_train_sc, y,\n",
      "  48:                     cv= StratifiedKFold(n_splits=5, shuffle=True),\n",
      "  49:                     scoring='accuracy').mean()\n",
      "  50:     print('Test accuracy:', c)\n",
      "  51:     return {'loss': -c, 'status': STATUS_OK, 'model': model}\n",
      "  52: \n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:                                       \n",
      "0.7552765968824364                                   \n",
      " 20%|██        | 1/5 [01:02<04:09, 62.49s/trial, best loss: -0.7552765968824364]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:                                                                  \n",
      "0.7692013582524531                                                              \n",
      " 40%|████      | 2/5 [01:40<02:24, 48.29s/trial, best loss: -0.7692013582524531]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:                                                                  \n",
      "0.7764605224459239                                                              \n",
      " 60%|██████    | 3/5 [02:26<01:34, 47.13s/trial, best loss: -0.7764605224459239]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:                                                                  \n",
      "0.7764765647977327                                                              \n",
      " 80%|████████  | 4/5 [02:53<00:39, 39.27s/trial, best loss: -0.7764765647977327]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:                                                                  \n",
      "0.7531295954653618                                                              \n",
      "100%|██████████| 5/5 [03:28<00:00, 41.78s/trial, best loss: -0.7764765647977327]\n"
     ]
    }
   ],
   "source": [
    "#call the optimisation algorithm\n",
    "best_run, best_model = optim.minimize(model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=50,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='ANN_Optimisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Activation': 0, 'Activation_1': 2, 'Dense': 4, 'Dense_1': 3, 'Dropout_rate': 0.12379862184321372, 'batch_size': 1, 'epochs': 1, 'learning_rate': 1}\n"
     ]
    }
   ],
   "source": [
    "#display the parameters for the best performing model\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 64)                1728      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,874\n",
      "Trainable params: 3,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Saved model to directory\n"
     ]
    }
   ],
   "source": [
    "#save resulting model in callable file\n",
    "best_model.summary()\n",
    "best_model.save('ANN Models/all_inputs_model.h5')\n",
    "print(\"Saved model to directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 47ms/step - loss: 0.7178 - accuracy: 0.4606 - val_loss: 0.5846 - val_accuracy: 0.7245\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5650 - accuracy: 0.7402 - val_loss: 0.5659 - val_accuracy: 0.7245\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7384 - val_loss: 0.5481 - val_accuracy: 0.7398\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7607 - val_loss: 0.5324 - val_accuracy: 0.7279\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7703 - val_loss: 0.5218 - val_accuracy: 0.7262\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7695 - val_loss: 0.5159 - val_accuracy: 0.7279\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.7702 - val_loss: 0.5112 - val_accuracy: 0.7262\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7648 - val_loss: 0.5077 - val_accuracy: 0.7381\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7644 - val_loss: 0.5053 - val_accuracy: 0.7296\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7704 - val_loss: 0.5041 - val_accuracy: 0.7313\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7769 - val_loss: 0.5029 - val_accuracy: 0.7330\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7744 - val_loss: 0.5019 - val_accuracy: 0.7347\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7869 - val_loss: 0.4996 - val_accuracy: 0.7347\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7795 - val_loss: 0.4984 - val_accuracy: 0.7296\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.7746 - val_loss: 0.4975 - val_accuracy: 0.7330\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7907 - val_loss: 0.4967 - val_accuracy: 0.7313\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7870 - val_loss: 0.4951 - val_accuracy: 0.7330\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7923 - val_loss: 0.4933 - val_accuracy: 0.7330\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7817 - val_loss: 0.4925 - val_accuracy: 0.7381\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7862 - val_loss: 0.4935 - val_accuracy: 0.7347\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7831 - val_loss: 0.4928 - val_accuracy: 0.7364\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7754 - val_loss: 0.4914 - val_accuracy: 0.7381\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7811 - val_loss: 0.4916 - val_accuracy: 0.7381\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8001 - val_loss: 0.4904 - val_accuracy: 0.7432\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7960 - val_loss: 0.4882 - val_accuracy: 0.7415\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8001 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7953 - val_loss: 0.4886 - val_accuracy: 0.7517\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7873 - val_loss: 0.4873 - val_accuracy: 0.7449\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.7855 - val_loss: 0.4874 - val_accuracy: 0.7432\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7975 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7751 - val_loss: 0.4863 - val_accuracy: 0.7449\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7964 - val_loss: 0.4861 - val_accuracy: 0.7466\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7916 - val_loss: 0.4870 - val_accuracy: 0.7449\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7966 - val_loss: 0.4861 - val_accuracy: 0.7483\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4313 - accuracy: 0.7976 - val_loss: 0.4864 - val_accuracy: 0.7483\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8033 - val_loss: 0.4867 - val_accuracy: 0.7517\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4259 - accuracy: 0.7966 - val_loss: 0.4879 - val_accuracy: 0.7551\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.8066 - val_loss: 0.4853 - val_accuracy: 0.7534\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.7982 - val_loss: 0.4858 - val_accuracy: 0.7551\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7937 - val_loss: 0.4859 - val_accuracy: 0.7551\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7958 - val_loss: 0.4851 - val_accuracy: 0.7534\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4221 - accuracy: 0.8013 - val_loss: 0.4843 - val_accuracy: 0.7551\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4197 - accuracy: 0.7946 - val_loss: 0.4849 - val_accuracy: 0.7551\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7995 - val_loss: 0.4844 - val_accuracy: 0.7602\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.7935 - val_loss: 0.4848 - val_accuracy: 0.7602\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8042 - val_loss: 0.4825 - val_accuracy: 0.7568\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.7951 - val_loss: 0.4831 - val_accuracy: 0.7602\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7949 - val_loss: 0.4833 - val_accuracy: 0.7602\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.7946 - val_loss: 0.4832 - val_accuracy: 0.7568\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8031 - val_loss: 0.4834 - val_accuracy: 0.7636\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4233 - accuracy: 0.7956 - val_loss: 0.4807 - val_accuracy: 0.7602\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7965 - val_loss: 0.4818 - val_accuracy: 0.7653\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8026 - val_loss: 0.4826 - val_accuracy: 0.7670\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8029 - val_loss: 0.4826 - val_accuracy: 0.7551\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7972 - val_loss: 0.4825 - val_accuracy: 0.7551\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8065 - val_loss: 0.4822 - val_accuracy: 0.7602\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8088 - val_loss: 0.4814 - val_accuracy: 0.7568\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8025 - val_loss: 0.4825 - val_accuracy: 0.7551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8012 - val_loss: 0.4825 - val_accuracy: 0.7568\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8010 - val_loss: 0.4821 - val_accuracy: 0.7568\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.7949 - val_loss: 0.4849 - val_accuracy: 0.7534\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7954 - val_loss: 0.4823 - val_accuracy: 0.7415\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.7976 - val_loss: 0.4826 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8014 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8067 - val_loss: 0.4853 - val_accuracy: 0.7432\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8003 - val_loss: 0.4832 - val_accuracy: 0.7449\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8053 - val_loss: 0.4859 - val_accuracy: 0.7415\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8024 - val_loss: 0.4801 - val_accuracy: 0.7517\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8055 - val_loss: 0.4840 - val_accuracy: 0.7551\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8150 - val_loss: 0.4818 - val_accuracy: 0.7551\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8033 - val_loss: 0.4858 - val_accuracy: 0.7551\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.7971 - val_loss: 0.4875 - val_accuracy: 0.7483\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8073 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8262 - val_loss: 0.4871 - val_accuracy: 0.7483\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.7981 - val_loss: 0.4863 - val_accuracy: 0.7466\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.8039 - val_loss: 0.4872 - val_accuracy: 0.7483\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8099 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.7965 - val_loss: 0.4849 - val_accuracy: 0.7585\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.7947 - val_loss: 0.4873 - val_accuracy: 0.7466\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8033 - val_loss: 0.4862 - val_accuracy: 0.7534\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8037 - val_loss: 0.4871 - val_accuracy: 0.7551\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8144 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.7975 - val_loss: 0.4890 - val_accuracy: 0.7602\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.7961 - val_loss: 0.4864 - val_accuracy: 0.7534\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8112 - val_loss: 0.4874 - val_accuracy: 0.7517\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8094 - val_loss: 0.4889 - val_accuracy: 0.7619\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8144 - val_loss: 0.4889 - val_accuracy: 0.7534\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8002 - val_loss: 0.4885 - val_accuracy: 0.7517\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8187 - val_loss: 0.4914 - val_accuracy: 0.7517\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8158 - val_loss: 0.4909 - val_accuracy: 0.7534\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8196 - val_loss: 0.4945 - val_accuracy: 0.7568\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8033 - val_loss: 0.4937 - val_accuracy: 0.7568\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8109 - val_loss: 0.4942 - val_accuracy: 0.7585\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8129 - val_loss: 0.4930 - val_accuracy: 0.7568\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8018 - val_loss: 0.4904 - val_accuracy: 0.7602\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8154 - val_loss: 0.4971 - val_accuracy: 0.7568\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8001 - val_loss: 0.4916 - val_accuracy: 0.7517\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8043 - val_loss: 0.4917 - val_accuracy: 0.7585\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8119 - val_loss: 0.4969 - val_accuracy: 0.7551\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8114 - val_loss: 0.4985 - val_accuracy: 0.7551\n"
     ]
    }
   ],
   "source": [
    "#train the model to gt learning curves\n",
    "batch=[32,64]\n",
    "ep=[50,100,200]\n",
    "\n",
    "history = best_model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=batch[best_run['batch_size']],\n",
    "    epochs=ep[best_run['epochs']],\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the labels for the test set\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer is encoded by [[0]] , while Control is encoded by [[1]]\n",
      "[[346  80]\n",
      " [ 64  98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.84      0.81      0.83       426\n",
      "     Control       0.55      0.60      0.58       162\n",
      "\n",
      "    accuracy                           0.76       588\n",
      "   macro avg       0.70      0.71      0.70       588\n",
      "weighted avg       0.76      0.76      0.76       588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate test performance of the model\n",
    "print('Cancer is encoded by',lb.transform(['Cancer']), ', while Control is encoded by',lb.transform(['Control']))\n",
    "print(confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(predictions, axis=1)))\n",
    "print(classification_report(np.argmax(Y_test, axis=1), np.argmax(predictions, axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Visualize history\n",
    "# Plot history: Loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: Accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Validation accuracy history')\n",
    "plt.ylabel('Accuracy value (%)')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer is encoded by [[0]] , while Control is encoded by [[1]]\n"
     ]
    }
   ],
   "source": [
    "print('Cancer is encoded by',lb.transform(['Cancer']), ', while Control is encoded by',lb.transform(['Control']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>9.954841e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.550455e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2.220592e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>3.295738e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index         Score\n",
       "0     21  9.954841e-09\n",
       "1      7  1.550455e-08\n",
       "2     17  2.220592e-08\n",
       "3     13  3.295738e-08"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dataframe = pd.read_csv(\"result.txt\",header = None)\n",
    "results_dataframe.columns=['Index','Score']\n",
    "results_dataframe['Index'] = results_dataframe['Index'].astype(int)\n",
    "results_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GP2', 'GP4'], dtype='object')\n",
      "[21, 7, 17, 13]\n",
      "Index(['GP22', 'GP8', 'GP18', 'GP14'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(features[[1,3]])\n",
    "print(results_dataframe['Index'].tolist())\n",
    "print(features[results_dataframe['Index'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_processed=results_dataframe.drop('Index',axis=1)\n",
    "results_processed.set_index(features[results_dataframe['Index'].tolist()],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP22</th>\n",
       "      <td>9.954841e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP8</th>\n",
       "      <td>1.550455e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP18</th>\n",
       "      <td>2.220592e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP14</th>\n",
       "      <td>3.295738e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Score\n",
       "GP22  9.954841e-09\n",
       "GP8   1.550455e-08\n",
       "GP18  2.220592e-08\n",
       "GP14  3.295738e-08"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_label': 0, 'pos_label': 1, 'sparse_output': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6580405235290527,\n",
       "  0.5750234723091125,\n",
       "  0.5507139563560486,\n",
       "  0.5292628407478333,\n",
       "  0.5134136080741882,\n",
       "  0.5023879408836365,\n",
       "  0.49226588010787964,\n",
       "  0.4870459735393524,\n",
       "  0.4857451021671295,\n",
       "  0.4814823269844055,\n",
       "  0.47681862115859985,\n",
       "  0.4728671610355377,\n",
       "  0.46941742300987244,\n",
       "  0.47409772872924805,\n",
       "  0.47158730030059814,\n",
       "  0.46569788455963135,\n",
       "  0.4634326696395874,\n",
       "  0.46181929111480713,\n",
       "  0.46001991629600525,\n",
       "  0.4592433571815491,\n",
       "  0.4617718756198883,\n",
       "  0.4574682116508484,\n",
       "  0.4575968384742737,\n",
       "  0.44773995876312256,\n",
       "  0.4493955671787262,\n",
       "  0.44413071870803833,\n",
       "  0.44487103819847107,\n",
       "  0.451716810464859,\n",
       "  0.4480264484882355,\n",
       "  0.4439697265625,\n",
       "  0.4432668685913086,\n",
       "  0.4404340982437134,\n",
       "  0.4430180788040161,\n",
       "  0.44510000944137573,\n",
       "  0.4361443519592285,\n",
       "  0.43062031269073486,\n",
       "  0.43133464455604553,\n",
       "  0.4317147731781006,\n",
       "  0.4303482174873352,\n",
       "  0.43297818303108215,\n",
       "  0.4278150200843811,\n",
       "  0.4294053316116333,\n",
       "  0.42770758271217346,\n",
       "  0.427034467458725,\n",
       "  0.42783889174461365,\n",
       "  0.430836945772171,\n",
       "  0.4232196509838104,\n",
       "  0.42462608218193054,\n",
       "  0.4189606010913849,\n",
       "  0.4221484363079071,\n",
       "  0.42193523049354553,\n",
       "  0.42537322640419006,\n",
       "  0.42059269547462463,\n",
       "  0.41656601428985596,\n",
       "  0.4173649847507477,\n",
       "  0.4136269688606262,\n",
       "  0.4127478003501892,\n",
       "  0.4171167016029358,\n",
       "  0.4171277582645416,\n",
       "  0.40936964750289917,\n",
       "  0.41122710704803467,\n",
       "  0.4137757420539856,\n",
       "  0.41142740845680237,\n",
       "  0.40785109996795654,\n",
       "  0.4032857120037079,\n",
       "  0.40360820293426514,\n",
       "  0.4007180333137512,\n",
       "  0.40837362408638,\n",
       "  0.40791055560112,\n",
       "  0.408330500125885,\n",
       "  0.40635302662849426,\n",
       "  0.4057382643222809,\n",
       "  0.4052533209323883,\n",
       "  0.3972691297531128,\n",
       "  0.3932555615901947,\n",
       "  0.3969704806804657,\n",
       "  0.39799898862838745,\n",
       "  0.3948385715484619,\n",
       "  0.3982117772102356,\n",
       "  0.39836108684539795,\n",
       "  0.39282920956611633,\n",
       "  0.38870057463645935,\n",
       "  0.39000001549720764,\n",
       "  0.39021825790405273,\n",
       "  0.38651207089424133,\n",
       "  0.38085561990737915,\n",
       "  0.3840824365615845,\n",
       "  0.3836531341075897,\n",
       "  0.3777588903903961,\n",
       "  0.39096516370773315,\n",
       "  0.38174691796302795,\n",
       "  0.3837815821170807,\n",
       "  0.37995660305023193,\n",
       "  0.38884788751602173,\n",
       "  0.3829156756401062,\n",
       "  0.3869399428367615,\n",
       "  0.38134244084358215,\n",
       "  0.38563451170921326,\n",
       "  0.36862850189208984,\n",
       "  0.37160417437553406],\n",
       " 'accuracy': [0.5953250527381897,\n",
       "  0.7253469824790955,\n",
       "  0.7231556177139282,\n",
       "  0.7384952306747437,\n",
       "  0.7560262680053711,\n",
       "  0.7552958130836487,\n",
       "  0.7567567825317383,\n",
       "  0.7567567825317383,\n",
       "  0.7545653581619263,\n",
       "  0.7618699669837952,\n",
       "  0.7662527561187744,\n",
       "  0.7684441208839417,\n",
       "  0.7757487297058105,\n",
       "  0.7713659405708313,\n",
       "  0.7618699669837952,\n",
       "  0.7779400944709778,\n",
       "  0.7808619141578674,\n",
       "  0.7757487297058105,\n",
       "  0.7728269100189209,\n",
       "  0.7735573649406433,\n",
       "  0.7779400944709778,\n",
       "  0.7728269100189209,\n",
       "  0.7720963954925537,\n",
       "  0.7874360680580139,\n",
       "  0.782322883605957,\n",
       "  0.7867056131362915,\n",
       "  0.7808619141578674,\n",
       "  0.7779400944709778,\n",
       "  0.7786705493927002,\n",
       "  0.7859751582145691,\n",
       "  0.7720963954925537,\n",
       "  0.7845142483711243,\n",
       "  0.7845142483711243,\n",
       "  0.7874360680580139,\n",
       "  0.7881665229797363,\n",
       "  0.7881665229797363,\n",
       "  0.7910884022712708,\n",
       "  0.7940102219581604,\n",
       "  0.7910884022712708,\n",
       "  0.7874360680580139,\n",
       "  0.7837837934494019,\n",
       "  0.7940102219581604,\n",
       "  0.7881665229797363,\n",
       "  0.7940102219581604,\n",
       "  0.7888969779014587,\n",
       "  0.7962015867233276,\n",
       "  0.7881665229797363,\n",
       "  0.7874360680580139,\n",
       "  0.7896274924278259,\n",
       "  0.7947406768798828,\n",
       "  0.7962015867233276,\n",
       "  0.7896274924278259,\n",
       "  0.79693204164505,\n",
       "  0.7925493121147156,\n",
       "  0.7983930110931396,\n",
       "  0.7991234660148621,\n",
       "  0.804236650466919,\n",
       "  0.8013148307800293,\n",
       "  0.7954711318016052,\n",
       "  0.79693204164505,\n",
       "  0.7947406768798828,\n",
       "  0.7918188571929932,\n",
       "  0.7918188571929932,\n",
       "  0.8013148307800293,\n",
       "  0.8056975603103638,\n",
       "  0.7991234660148621,\n",
       "  0.7983930110931396,\n",
       "  0.793279767036438,\n",
       "  0.7947406768798828,\n",
       "  0.8086194396018982,\n",
       "  0.7962015867233276,\n",
       "  0.7976625561714172,\n",
       "  0.8035061955451965,\n",
       "  0.8137326240539551,\n",
       "  0.7983930110931396,\n",
       "  0.804236650466919,\n",
       "  0.8086194396018982,\n",
       "  0.8013148307800293,\n",
       "  0.7954711318016052,\n",
       "  0.8020452857017517,\n",
       "  0.8020452857017517,\n",
       "  0.8137326240539551,\n",
       "  0.7947406768798828,\n",
       "  0.8056975603103638,\n",
       "  0.8056975603103638,\n",
       "  0.8086194396018982,\n",
       "  0.8093498945236206,\n",
       "  0.8020452857017517,\n",
       "  0.8151935935020447,\n",
       "  0.8115412592887878,\n",
       "  0.821037232875824,\n",
       "  0.8035061955451965,\n",
       "  0.8071585297584534,\n",
       "  0.810080349445343,\n",
       "  0.8071585297584534,\n",
       "  0.8108108043670654,\n",
       "  0.806428074836731,\n",
       "  0.8027757406234741,\n",
       "  0.806428074836731,\n",
       "  0.8166545033454895],\n",
       " 'val_loss': [0.5846145749092102,\n",
       "  0.5658926367759705,\n",
       "  0.548097550868988,\n",
       "  0.5323522686958313,\n",
       "  0.5217552185058594,\n",
       "  0.5158782005310059,\n",
       "  0.5111774802207947,\n",
       "  0.5077243447303772,\n",
       "  0.5053163766860962,\n",
       "  0.5040733218193054,\n",
       "  0.5029035210609436,\n",
       "  0.5018898844718933,\n",
       "  0.4995810091495514,\n",
       "  0.4984104335308075,\n",
       "  0.49745675921440125,\n",
       "  0.496714323759079,\n",
       "  0.4951324462890625,\n",
       "  0.4932817220687866,\n",
       "  0.4925287067890167,\n",
       "  0.4934864044189453,\n",
       "  0.4928107261657715,\n",
       "  0.49135714769363403,\n",
       "  0.491646945476532,\n",
       "  0.49042943120002747,\n",
       "  0.48819321393966675,\n",
       "  0.4887750446796417,\n",
       "  0.48856592178344727,\n",
       "  0.48729804158210754,\n",
       "  0.4874451756477356,\n",
       "  0.4872875511646271,\n",
       "  0.4862743020057678,\n",
       "  0.48611757159233093,\n",
       "  0.4869811534881592,\n",
       "  0.4860858619213104,\n",
       "  0.48638755083084106,\n",
       "  0.4866751432418823,\n",
       "  0.4879218339920044,\n",
       "  0.4852902293205261,\n",
       "  0.4857921004295349,\n",
       "  0.4858644902706146,\n",
       "  0.48507943749427795,\n",
       "  0.48427727818489075,\n",
       "  0.48485836386680603,\n",
       "  0.4843990206718445,\n",
       "  0.48478153347969055,\n",
       "  0.4824639558792114,\n",
       "  0.48311033844947815,\n",
       "  0.48331862688064575,\n",
       "  0.4832119047641754,\n",
       "  0.4833700358867645,\n",
       "  0.4807294011116028,\n",
       "  0.48177021741867065,\n",
       "  0.48264604806900024,\n",
       "  0.48258256912231445,\n",
       "  0.4824599325656891,\n",
       "  0.48217010498046875,\n",
       "  0.4813976287841797,\n",
       "  0.4825137257575989,\n",
       "  0.48249438405036926,\n",
       "  0.4820666015148163,\n",
       "  0.4848502576351166,\n",
       "  0.4822799861431122,\n",
       "  0.48260611295700073,\n",
       "  0.48420196771621704,\n",
       "  0.4853355884552002,\n",
       "  0.48319903016090393,\n",
       "  0.48586755990982056,\n",
       "  0.4800781309604645,\n",
       "  0.4840305745601654,\n",
       "  0.4818214774131775,\n",
       "  0.4857886731624603,\n",
       "  0.4874747693538666,\n",
       "  0.4863927364349365,\n",
       "  0.48705410957336426,\n",
       "  0.486268013715744,\n",
       "  0.48716533184051514,\n",
       "  0.4863344132900238,\n",
       "  0.48485374450683594,\n",
       "  0.4873335063457489,\n",
       "  0.4862208962440491,\n",
       "  0.4870844781398773,\n",
       "  0.4872809648513794,\n",
       "  0.488993376493454,\n",
       "  0.4863796532154083,\n",
       "  0.4874267578125,\n",
       "  0.4889219105243683,\n",
       "  0.48888853192329407,\n",
       "  0.48854050040245056,\n",
       "  0.4914211332798004,\n",
       "  0.4908652901649475,\n",
       "  0.49446916580200195,\n",
       "  0.49369651079177856,\n",
       "  0.4942208230495453,\n",
       "  0.49304094910621643,\n",
       "  0.49038243293762207,\n",
       "  0.49710312485694885,\n",
       "  0.4916442930698395,\n",
       "  0.49174246191978455,\n",
       "  0.496926873922348,\n",
       "  0.4984757900238037],\n",
       " 'val_accuracy': [0.7244898080825806,\n",
       "  0.7244898080825806,\n",
       "  0.7397959232330322,\n",
       "  0.7278911471366882,\n",
       "  0.726190447807312,\n",
       "  0.7278911471366882,\n",
       "  0.726190447807312,\n",
       "  0.738095223903656,\n",
       "  0.7295918464660645,\n",
       "  0.7312925457954407,\n",
       "  0.7329931855201721,\n",
       "  0.7346938848495483,\n",
       "  0.7346938848495483,\n",
       "  0.7295918464660645,\n",
       "  0.7329931855201721,\n",
       "  0.7312925457954407,\n",
       "  0.7329931855201721,\n",
       "  0.7329931855201721,\n",
       "  0.738095223903656,\n",
       "  0.7346938848495483,\n",
       "  0.7363945841789246,\n",
       "  0.738095223903656,\n",
       "  0.738095223903656,\n",
       "  0.7431972622871399,\n",
       "  0.7414966225624084,\n",
       "  0.75,\n",
       "  0.7517006993293762,\n",
       "  0.7448979616165161,\n",
       "  0.7431972622871399,\n",
       "  0.75,\n",
       "  0.7448979616165161,\n",
       "  0.7465986609458923,\n",
       "  0.7448979616165161,\n",
       "  0.7482993006706238,\n",
       "  0.7482993006706238,\n",
       "  0.7517006993293762,\n",
       "  0.7551020383834839,\n",
       "  0.7534013390541077,\n",
       "  0.7551020383834839,\n",
       "  0.7551020383834839,\n",
       "  0.7534013390541077,\n",
       "  0.7551020383834839,\n",
       "  0.7551020383834839,\n",
       "  0.7602040767669678,\n",
       "  0.7602040767669678,\n",
       "  0.7568027377128601,\n",
       "  0.7602040767669678,\n",
       "  0.7602040767669678,\n",
       "  0.7568027377128601,\n",
       "  0.7636054158210754,\n",
       "  0.7602040767669678,\n",
       "  0.7653061151504517,\n",
       "  0.7670068144798279,\n",
       "  0.7551020383834839,\n",
       "  0.7551020383834839,\n",
       "  0.7602040767669678,\n",
       "  0.7568027377128601,\n",
       "  0.7551020383834839,\n",
       "  0.7568027377128601,\n",
       "  0.7568027377128601,\n",
       "  0.7534013390541077,\n",
       "  0.7414966225624084,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7431972622871399,\n",
       "  0.7448979616165161,\n",
       "  0.7414966225624084,\n",
       "  0.7517006993293762,\n",
       "  0.7551020383834839,\n",
       "  0.7551020383834839,\n",
       "  0.7551020383834839,\n",
       "  0.7482993006706238,\n",
       "  0.75,\n",
       "  0.7482993006706238,\n",
       "  0.7465986609458923,\n",
       "  0.7482993006706238,\n",
       "  0.75,\n",
       "  0.7585033774375916,\n",
       "  0.7465986609458923,\n",
       "  0.7534013390541077,\n",
       "  0.7551020383834839,\n",
       "  0.75,\n",
       "  0.7602040767669678,\n",
       "  0.7534013390541077,\n",
       "  0.7517006993293762,\n",
       "  0.761904776096344,\n",
       "  0.7534013390541077,\n",
       "  0.7517006993293762,\n",
       "  0.7517006993293762,\n",
       "  0.7534013390541077,\n",
       "  0.7568027377128601,\n",
       "  0.7568027377128601,\n",
       "  0.7585033774375916,\n",
       "  0.7568027377128601,\n",
       "  0.7602040767669678,\n",
       "  0.7568027377128601,\n",
       "  0.7517006993293762,\n",
       "  0.7585033774375916,\n",
       "  0.7551020383834839,\n",
       "  0.7551020383834839]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
