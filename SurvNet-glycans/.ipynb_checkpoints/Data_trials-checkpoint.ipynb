{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac6af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alext\\anaconda3\\envs\\SurvNetEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\SurvNetEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\SurvNetEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\SurvNetEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\SurvNetEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Alext\\anaconda3\\envs\\SurvNetEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import  StandardScaler, LabelEncoder, OneHotEncoder, LabelBinarizer, MinMaxScaler, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e3daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X, train_Y, val_X, val_Y, test_X, test_Y, lb = data()\n",
    "\n",
    "seed=1 # set a seed\n",
    "np.random.seed(seed)\n",
    "whole_X=np.random.uniform(0,1,(1900,28))\n",
    "n=whole_X.shape[0]\n",
    "p0=whole_X.shape[1] # the number of original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fb61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "art=np.array(random.sample(range(p0),10)) # the indexes of significant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c63f7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the variables significant by shifting their values at half of the samples\n",
    "np.random.seed(seed)\n",
    "sign=np.random.choice([-1,1],len(art))\n",
    "u=np.random.uniform(0.1,0.3,len(art))\n",
    "u=u*sign\n",
    "mat=np.reshape(np.tile(u,int(0.5*n)),(int(0.5*n),len(art)))\n",
    "whole_X[:int(0.5*n),art]=whole_X[:int(0.5*n),art]+mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53dc3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels\n",
    "whole_Y=np.zeros((n,2))\n",
    "whole_Y[:int(0.5*n),0]=1\n",
    "whole_Y[int(0.5*n):,1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c134333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permute (shuffle) and standardize the data\n",
    "t=np.random.RandomState(seed).permutation(n)\n",
    "whole_X=whole_X[t]\n",
    "whole_Y=whole_Y[t]\n",
    "whole_X=preprocessing.scale(whole_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a941ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "train_X=whole_X[:int(0.8*0.7*n)]\n",
    "train_Y=whole_Y[:int(0.8*0.7*n)]\n",
    "val_X=whole_X[int(0.8*0.7*n):int(0.8*n)]\n",
    "val_Y=whole_Y[int(0.8*0.7*n):int(0.8*n)]\n",
    "test_X=whole_X[int(0.8*n):]\n",
    "test_Y=whole_Y[int(0.8*n):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f461db75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87329573, -1.44324436,  0.81153141, ..., -0.73834841,\n",
       "        -0.15128311, -0.93853261],\n",
       "       [ 1.16797989, -1.39601828, -0.72136325, ...,  0.14389252,\n",
       "         0.5797688 , -1.57298542],\n",
       "       [-1.23807199, -0.94253513, -0.87217423, ...,  0.46124848,\n",
       "         0.27846806, -0.37127371],\n",
       "       ...,\n",
       "       [ 1.74921042,  1.61597942, -1.34783588, ..., -0.42020446,\n",
       "        -0.65669324,  0.1893029 ],\n",
       "       [ 0.11059884, -0.8583228 ,  0.51963101, ..., -0.56545262,\n",
       "         1.69962963, -0.93356977],\n",
       "       [-0.36926745, -1.08250683, -0.90500698, ...,  1.34702218,\n",
       "        -0.71989324, -0.86034265]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89bfadba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e832cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data function for reading and processing the train and test sets\n",
    "#necessary as an input for the optimisation algorithm\n",
    "def data():\n",
    "    #define input processing function\n",
    "    def process_attributes(df, train, val, test):\n",
    "        \n",
    "        #define and fit the scaler to the full dataset\n",
    "        cs = MinMaxScaler()\n",
    "        cs.fit(df_inputs.select_dtypes(np.number))\n",
    "        \n",
    "        #scale the numerical input variables\n",
    "        trainContinuous = cs.transform(train.select_dtypes(np.number))\n",
    "        valContinuous = cs.transform(val.select_dtypes(np.number))\n",
    "        testContinuous = cs.transform(test.select_dtypes(np.number))\n",
    "        \n",
    "        #uncomment the code below to accommodate for any categorical columns\n",
    "        zipBinarizer = LabelBinarizer().fit(df[\"Gender\"])\n",
    "        trainCategorical = zipBinarizer.transform(train[\"Gender\"])\n",
    "        valCategorical = zipBinarizer.transform(val[\"Gender\"])\n",
    "        testCategorical = zipBinarizer.transform(test[\"Gender\"])\n",
    "        \n",
    "        # construct our training and testing data points by concatenating\n",
    "        # the categorical features with the continuous features\n",
    "        trainX = np.hstack([trainContinuous, trainCategorical])\n",
    "        valX = np.hstack([valContinuous, valCategorical])\n",
    "        testX = np.hstack([testContinuous, testCategorical])\n",
    "        \n",
    "        \n",
    "        # return the concatenated training and testing data\n",
    "        return (trainX, valX, testX)\n",
    "    \n",
    "    #read the excel datasets\n",
    "    df = pd.read_excel('Cleaned_Dataframe.xlsx')\n",
    "    df.set_index('Sample',inplace=True)\n",
    "\n",
    "\n",
    "    #separate cancer markers and input data\n",
    "    df_outputs= df['Status']\n",
    "    df_inputs = df.drop('Status',axis=1)\n",
    "    \n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(df_inputs, df_outputs, random_state=100, stratify=df_outputs, test_size=0.4)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, random_state=100, stratify=y_test_val, test_size=0.5)\n",
    "    #process the input sets\n",
    "    (X_train_sc, X_val_sc, X_test_sc) = process_attributes(df_inputs, X_train, X_val, X_test)\n",
    "    \n",
    "    #encode the categorical output variables\n",
    "    #encode categorical outputs\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    train_outputs= lb.transform(y_train)\n",
    "    val_outputs= lb.transform(y_val)\n",
    "    test_outputs= lb.transform(y_test)\n",
    "    \n",
    "    lb2=MultiLabelBinarizer()\n",
    "    lb2.fit(train_outputs)\n",
    "    Y_train = lb2.transform(train_outputs)\n",
    "    Y_val = lb2.transform(val_outputs)\n",
    "    Y_test = lb2.transform(test_outputs)\n",
    "    #Y_train = to_categorical(train_outputs)\n",
    "    #Y_val = to_categorical(val_outputs)\n",
    "    #Y_test = to_categorical(test_outputs)\n",
    "\n",
    "    return X_train_sc, Y_train, X_val_sc, Y_val, X_test_sc, Y_test, lb\n",
    "\n",
    "train_X2, train_Y2, val_X2, val_Y2, test_X2, test_Y2, lb = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e50cb6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1957 samples in total with 26 features\n"
     ]
    }
   ],
   "source": [
    "print('there are',len(train_X2)+len(test_X2)+len(val_X2), 'samples in total', 'with', train_X2.shape[1], 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d0d45f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c172f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0d3bc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim=train_X2.shape[1]\n",
    "No=np.array(range(n_dim))\n",
    "No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6e645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
